{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Project Pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Token\n",
    "from spacy.tokens import Doc\n",
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordfreq import zipf_frequency\n",
    "from wordfreq import word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "\n",
    "phoneme_dict = dict(cmudict.entries())\n",
    "\n",
    "def syllable_counter(word):\n",
    "    '''function that counts a syllable in a word'''\n",
    "    if word not in phoneme_dict:\n",
    "        return 0\n",
    "    syllables = phoneme_dict[word]\n",
    "    count = len([syllable for syllable in syllables if syllable[-1].isdigit()])\n",
    "    return round(count, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.0\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = '../data/kafka.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(open(text_file, \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcount(doc):\n",
    "    '''gives an overall word count'''\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            doc._.wordcount += 1\n",
    "    \n",
    "    print(f'{doc._.wordcount} words in document')\n",
    "         \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tokens(doc):\n",
    "    '''filters all tokens'''           \n",
    "    \n",
    "    \n",
    "    for token in doc:\n",
    "        # filter stopwords\n",
    "        if not token.is_alpha or token.is_stop:\n",
    "            token._.is_excluded = True\n",
    "            \n",
    "        # filter part-of-speech\n",
    "        elif token.pos_ not in ['NOUN', 'VERB', 'ADJ']:\n",
    "            token._.is_excluded = True\n",
    "            \n",
    "        # filter entities\n",
    "        elif token.ent_type != 0:\n",
    "                token._.is_excluded = True\n",
    "                \n",
    "        # count included words   \n",
    "        else:\n",
    "            doc._.included_wordcount += 1\n",
    "\n",
    "    print(f'{doc._.included_wordcount} words in vocabulary')\n",
    "         \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elim_dup(doc):\n",
    "    '''eliminates all duplicates and counts the appearance of the included words'''\n",
    "    already_appeared = {}\n",
    "\n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            if token.lemma_ in already_appeared.keys():\n",
    "                already_appeared[token.lemma_]._.appearance += 1\n",
    "                token._.is_excluded = True\n",
    "                doc._.included_wordcount -= 1\n",
    "            else:\n",
    "                token._.appearance = 1\n",
    "                already_appeared[token.lemma_] = token\n",
    "    \n",
    "    print(f'{doc._.included_wordcount} words in vocabulary without duplicates')\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Difficulty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syl_weight(n):\n",
    "    w = 0\n",
    "    for i in range(n):\n",
    "        w += 0.5**(i+1)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difficulty(doc):\n",
    "   \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            lemma = token.lemma_\n",
    "            difficulty = 8 - zipf_frequency(lemma, 'en') # score of 0-8\n",
    "            difficulty += syl_weight(syllable_counter(lemma)) # now score of 0-9\n",
    "            token._.difficulty = round(difficulty/9, 3) #normalised to 0-1\n",
    "            \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Freqency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relativ_freq(doc):\n",
    "    '''calculating the relativ frequency of a included word'''\n",
    "    \n",
    "    maw = 20 # maximal appearance weight\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            text_freq = min(maw, token._.appearance) / doc._.wordcount\n",
    "            overall_freq = word_frequency(token.lemma_, 'en')\n",
    "            if overall_freq != 0:\n",
    "                token._.relativ_freq = round(text_freq**2 / overall_freq, 3)\n",
    "        \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_keyphrases(doc):\n",
    "    \n",
    "    #TODO: was ist mit den fehlenden Wortvektoren\n",
    "    \n",
    "    kw = keywords(doc.text, split=True)\n",
    "    \n",
    "    keywords_token = []\n",
    "    already_in_list = []\n",
    "    for token in doc:\n",
    "        if token.text in kw:\n",
    "            token._.is_keyword = True\n",
    "            if token.text not in already_in_list:\n",
    "                keywords_token.append(token)\n",
    "                already_in_list.append(token.text)\n",
    "    doc._.keywords = keywords_token\n",
    "    \n",
    "    print(f'{len(keywords_token)} words are keywords')\n",
    "    \n",
    "    for token in doc:\n",
    "        for kw in keywords_token:\n",
    "            kw_score = token.similarity(kw)\n",
    "            if kw_score > token._.keyword_score:\n",
    "                token._.keyword_score =  kw_score\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline():\n",
    "    nlp = spacy.load('en_core_web_lg', disable = ['parser'])\n",
    "    \n",
    "    ## Preprocessing\n",
    "    # wordcount\n",
    "    Doc.set_extension('wordcount', default=0, force=True)\n",
    "    nlp.add_pipe(wordcount)\n",
    "    \n",
    "    # filter tokens\n",
    "    Doc.set_extension('included_wordcount', default=0, force=True)\n",
    "    Token.set_extension('is_excluded', default=False, force=True)\n",
    "    nlp.add_pipe(filter_tokens)\n",
    "    \n",
    "    # eliminate dublicates\n",
    "    Token.set_extension('appearance', default=np.nan, force=True)\n",
    "    nlp.add_pipe(elim_dup)\n",
    "    \n",
    "    \n",
    "    ## Word difficulty\n",
    "    # difficulty\n",
    "    Token.set_extension('difficulty', default=0, force=True)\n",
    "    nlp.add_pipe(get_difficulty)\n",
    "    \n",
    "    # relative frequency\n",
    "    Token.set_extension('relativ_freq', default=np.nan, force=True)\n",
    "    nlp.add_pipe(calculate_relativ_freq)\n",
    "    \n",
    "    \n",
    "    ## Word Relevance\n",
    "    # keywordscore\n",
    "    Doc.set_extension('keywords', default=[], force=True)\n",
    "    Token.set_extension('is_keyword', default=False, force=True)\n",
    "    Token.set_extension('keyword_score', default=0, force=True)\n",
    "    # nlp.add_pipe(check_keyphrases)\n",
    "    \n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger',\n",
       " 'ner',\n",
       " 'wordcount',\n",
       " 'filter_tokens',\n",
       " 'elim_dup',\n",
       " 'get_difficulty',\n",
       " 'calculate_relativ_freq']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = create_pipeline()\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_doc(doc):\n",
    "    data = []\n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            data.append((token, token.lemma_, token._.appearance, token._.difficulty, token._.relativ_freq, token._.keyword_score, token._.is_keyword))\n",
    "    df = pd.DataFrame(data, columns=['token', 'lemma', 'appearance', 'difficulty', 'relativ freqency', 'keyword score', 'is keyword'])\n",
    "    \n",
    "    df[['difficulty_rank', 'keyword_rank']] = df[['difficulty', 'keyword score']].rank(ascending=False)\n",
    "    \n",
    "    df['overall_ranking'] = df['difficulty']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test scentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 words in document\n",
      "9 words in vocabulary\n",
      "6 words in vocabulary without duplicates\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Hi I'm a little little boy. Get me a piece of cake or I'll killed your mother. I am the mother of your mother\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_from_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>keyword score</th>\n",
       "      <th>is keyword</th>\n",
       "      <th>difficulty_rank</th>\n",
       "      <th>keyword_rank</th>\n",
       "      <th>overall_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cake</td>\n",
       "      <td>cake</td>\n",
       "      <td>1</td>\n",
       "      <td>0.452</td>\n",
       "      <td>64.539</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>piece</td>\n",
       "      <td>piece</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392</td>\n",
       "      <td>18.608</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mother</td>\n",
       "      <td>mother</td>\n",
       "      <td>3</td>\n",
       "      <td>0.386</td>\n",
       "      <td>81.806</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>killed</td>\n",
       "      <td>kill</td>\n",
       "      <td>1</td>\n",
       "      <td>0.379</td>\n",
       "      <td>14.115</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy</td>\n",
       "      <td>boy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.367</td>\n",
       "      <td>10.988</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333</td>\n",
       "      <td>12.357</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token   lemma  appearance  difficulty  relativ freqency  keyword score  \\\n",
       "3    cake    cake           1       0.452            64.539              0   \n",
       "2   piece   piece           1       0.392            18.608              0   \n",
       "5  mother  mother           3       0.386            81.806              0   \n",
       "4  killed    kill           1       0.379            14.115              0   \n",
       "1     boy     boy           1       0.367            10.988              0   \n",
       "0  little  little           2       0.333            12.357              0   \n",
       "\n",
       "   is keyword  difficulty_rank  keyword_rank  overall_ranking  \n",
       "3       False              1.0           3.5            0.452  \n",
       "2       False              2.0           3.5            0.392  \n",
       "5       False              3.0           3.5            0.386  \n",
       "4       False              4.0           3.5            0.379  \n",
       "1       False              5.0           3.5            0.367  \n",
       "0       False              6.0           3.5            0.333  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['overall_ranking'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25062 words in document\n",
      "7812 words in vocabulary\n",
      "1873 words in vocabulary without duplicates\n"
     ]
    }
   ],
   "source": [
    "with open(text_file, \"r\") as f:\n",
    "    doc = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_from_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>keyword score</th>\n",
       "      <th>is keyword</th>\n",
       "      <th>difficulty_rank</th>\n",
       "      <th>keyword_rank</th>\n",
       "      <th>overall_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>teaboy</td>\n",
       "      <td>teaboy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>startlement</td>\n",
       "      <td>startlement</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>soughing</td>\n",
       "      <td>soughing</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>swinging</td>\n",
       "      <td>swinge</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>fretsaw</td>\n",
       "      <td>fretsaw</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>times</td>\n",
       "      <td>time</td>\n",
       "      <td>74</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1869.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "      <td>12</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>wo</td>\n",
       "      <td>will</td>\n",
       "      <td>1</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>ones</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>having</td>\n",
       "      <td>have</td>\n",
       "      <td>8</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1873 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            token        lemma  appearance  difficulty  relativ freqency  \\\n",
       "1358       teaboy       teaboy           1       0.889               NaN   \n",
       "1166  startlement  startlement           1       0.889               NaN   \n",
       "655      soughing     soughing           1       0.889               NaN   \n",
       "396      swinging       swinge           1       0.889               NaN   \n",
       "497       fretsaw      fretsaw           1       0.889               NaN   \n",
       "...           ...          ...         ...         ...               ...   \n",
       "117         times         time          74       0.247               0.0   \n",
       "32           like         like          12       0.234               0.0   \n",
       "1133           wo         will           1       0.228               0.0   \n",
       "1296         ones          one           1       0.224               0.0   \n",
       "240        having         have           8       0.200               0.0   \n",
       "\n",
       "      keyword score  is keyword  difficulty_rank  keyword_rank  \\\n",
       "1358              0       False              3.0         937.0   \n",
       "1166              0       False              3.0         937.0   \n",
       "655               0       False              3.0         937.0   \n",
       "396               0       False              3.0         937.0   \n",
       "497               0       False              3.0         937.0   \n",
       "...             ...         ...              ...           ...   \n",
       "117               0       False           1869.0         937.0   \n",
       "32                0       False           1870.0         937.0   \n",
       "1133              0       False           1871.0         937.0   \n",
       "1296              0       False           1872.0         937.0   \n",
       "240               0       False           1873.0         937.0   \n",
       "\n",
       "      overall_ranking  \n",
       "1358            0.889  \n",
       "1166            0.889  \n",
       "655             0.889  \n",
       "396             0.889  \n",
       "497             0.889  \n",
       "...               ...  \n",
       "117             0.247  \n",
       "32              0.234  \n",
       "1133            0.228  \n",
       "1296            0.224  \n",
       "240             0.200  \n",
       "\n",
       "[1873 rows x 10 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['overall_ranking'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>swinging</td>\n",
       "      <td>swinge</td>\n",
       "      <td>1</td>\n",
       "      <td>8.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>saddened</td>\n",
       "      <td>sadden</td>\n",
       "      <td>1</td>\n",
       "      <td>5.97</td>\n",
       "      <td>0.014879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>assailed</td>\n",
       "      <td>assail</td>\n",
       "      <td>1</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>hearer</td>\n",
       "      <td>hearer</td>\n",
       "      <td>1</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>rumination</td>\n",
       "      <td>rumination</td>\n",
       "      <td>1</td>\n",
       "      <td>5.82</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>incarcerated</td>\n",
       "      <td>incarcerate</td>\n",
       "      <td>1</td>\n",
       "      <td>5.81</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>perversity</td>\n",
       "      <td>perversity</td>\n",
       "      <td>1</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>construed</td>\n",
       "      <td>construe</td>\n",
       "      <td>1</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>unthinking</td>\n",
       "      <td>unthinking</td>\n",
       "      <td>1</td>\n",
       "      <td>5.74</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>protrusions</td>\n",
       "      <td>protrusion</td>\n",
       "      <td>1</td>\n",
       "      <td>5.68</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>resounding</td>\n",
       "      <td>resound</td>\n",
       "      <td>1</td>\n",
       "      <td>5.65</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>disclaim</td>\n",
       "      <td>disclaim</td>\n",
       "      <td>1</td>\n",
       "      <td>5.59</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>protruding</td>\n",
       "      <td>protrude</td>\n",
       "      <td>2</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>flecks</td>\n",
       "      <td>fleck</td>\n",
       "      <td>1</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>indemnify</td>\n",
       "      <td>indemnify</td>\n",
       "      <td>1</td>\n",
       "      <td>5.56</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>invalidity</td>\n",
       "      <td>invalidity</td>\n",
       "      <td>1</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>proofread</td>\n",
       "      <td>proofread</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>unpleasantness</td>\n",
       "      <td>unpleasantness</td>\n",
       "      <td>1</td>\n",
       "      <td>5.47</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>captivate</td>\n",
       "      <td>captivate</td>\n",
       "      <td>1</td>\n",
       "      <td>5.41</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>groundless</td>\n",
       "      <td>groundless</td>\n",
       "      <td>1</td>\n",
       "      <td>5.41</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               token           lemma  appearance  difficulty  \\\n",
       "302         swinging          swinge           1        8.00   \n",
       "827         saddened          sadden           1        5.97   \n",
       "858         assailed          assail           1        5.91   \n",
       "203           hearer          hearer           1        5.90   \n",
       "1146      rumination      rumination           1        5.82   \n",
       "735     incarcerated     incarcerate           1        5.81   \n",
       "846       perversity      perversity           1        5.76   \n",
       "711        construed        construe           1        5.76   \n",
       "582       unthinking      unthinking           1        5.74   \n",
       "923      protrusions      protrusion           1        5.68   \n",
       "589       resounding         resound           1        5.65   \n",
       "1331        disclaim        disclaim           1        5.59   \n",
       "554       protruding        protrude           2        5.57   \n",
       "617           flecks           fleck           1        5.57   \n",
       "1361       indemnify       indemnify           1        5.56   \n",
       "1358      invalidity      invalidity           1        5.54   \n",
       "1314       proofread       proofread           1        5.52   \n",
       "666   unpleasantness  unpleasantness           1        5.47   \n",
       "1085       captivate       captivate           1        5.41   \n",
       "545       groundless      groundless           1        5.41   \n",
       "\n",
       "      relativ freqency  cluster  \n",
       "302                NaN        6  \n",
       "827           0.014879        4  \n",
       "858           0.012944        4  \n",
       "203           0.012636        4  \n",
       "1146          0.010544        4  \n",
       "735           0.010272        4  \n",
       "846           0.009150        4  \n",
       "711           0.009150        7  \n",
       "582           0.008748        4  \n",
       "923           0.007618        6  \n",
       "589           0.007108        4  \n",
       "1331          0.006195        7  \n",
       "554           0.023674        6  \n",
       "617           0.005919        6  \n",
       "1361          0.005789        7  \n",
       "1358          0.005528        7  \n",
       "1314          0.005272        9  \n",
       "666           0.004696        4  \n",
       "1085          0.004093        4  \n",
       "545           0.004093        4  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['difficulty'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>distribute</td>\n",
       "      <td>distribute</td>\n",
       "      <td>17</td>\n",
       "      <td>4.21</td>\n",
       "      <td>0.074573</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>locksmith</td>\n",
       "      <td>locksmith</td>\n",
       "      <td>4</td>\n",
       "      <td>5.35</td>\n",
       "      <td>0.056988</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>donations</td>\n",
       "      <td>donation</td>\n",
       "      <td>16</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.043684</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>violin</td>\n",
       "      <td>violin</td>\n",
       "      <td>12</td>\n",
       "      <td>4.28</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>COPYRIGHTED</td>\n",
       "      <td>copyright</td>\n",
       "      <td>21</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>couch</td>\n",
       "      <td>couch</td>\n",
       "      <td>17</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0.035668</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>trademark</td>\n",
       "      <td>trademark</td>\n",
       "      <td>11</td>\n",
       "      <td>4.14</td>\n",
       "      <td>0.026608</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>clothes</td>\n",
       "      <td>clothe</td>\n",
       "      <td>3</td>\n",
       "      <td>5.23</td>\n",
       "      <td>0.024327</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>protruding</td>\n",
       "      <td>protrude</td>\n",
       "      <td>2</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>refund</td>\n",
       "      <td>refund</td>\n",
       "      <td>9</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>painfully</td>\n",
       "      <td>painfully</td>\n",
       "      <td>6</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>parents</td>\n",
       "      <td>parent</td>\n",
       "      <td>26</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.017119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>slowly</td>\n",
       "      <td>slowly</td>\n",
       "      <td>22</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.015272</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>saddened</td>\n",
       "      <td>sadden</td>\n",
       "      <td>1</td>\n",
       "      <td>5.97</td>\n",
       "      <td>0.014879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>complying</td>\n",
       "      <td>comply</td>\n",
       "      <td>9</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.014474</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>broom</td>\n",
       "      <td>broom</td>\n",
       "      <td>5</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.014114</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>disturbed</td>\n",
       "      <td>disturb</td>\n",
       "      <td>6</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.013745</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>paragraph</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>11</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>legs</td>\n",
       "      <td>leg</td>\n",
       "      <td>21</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.013295</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>assailed</td>\n",
       "      <td>assail</td>\n",
       "      <td>1</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>astonished</td>\n",
       "      <td>astonished</td>\n",
       "      <td>4</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0.012737</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>hearer</td>\n",
       "      <td>hearer</td>\n",
       "      <td>1</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>reproach</td>\n",
       "      <td>reproach</td>\n",
       "      <td>3</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>DISCLAIMER</td>\n",
       "      <td>disclaimer</td>\n",
       "      <td>4</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.011904</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>hardly</td>\n",
       "      <td>hardly</td>\n",
       "      <td>16</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.011746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>copy</td>\n",
       "      <td>copy</td>\n",
       "      <td>24</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>redistributing</td>\n",
       "      <td>redistribute</td>\n",
       "      <td>2</td>\n",
       "      <td>5.22</td>\n",
       "      <td>0.010561</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>rumination</td>\n",
       "      <td>rumination</td>\n",
       "      <td>1</td>\n",
       "      <td>5.82</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>incarcerated</td>\n",
       "      <td>incarcerate</td>\n",
       "      <td>1</td>\n",
       "      <td>5.81</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>chest</td>\n",
       "      <td>chest</td>\n",
       "      <td>14</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.009875</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               token         lemma  appearance  difficulty  relativ freqency  \\\n",
       "1208      distribute    distribute          17        4.21          0.074573   \n",
       "461        locksmith     locksmith           4        5.35          0.056988   \n",
       "1297       donations      donation          16        4.03          0.043684   \n",
       "780           violin        violin          12        4.28          0.043669   \n",
       "10       COPYRIGHTED     copyright          21        3.76          0.036600   \n",
       "656            couch         couch          17        3.89          0.035668   \n",
       "1214       trademark     trademark          11        4.14          0.026608   \n",
       "777          clothes        clothe           3        5.23          0.024327   \n",
       "554       protruding      protrude           2        5.57          0.023674   \n",
       "1238          refund        refund           9        4.22          0.021386   \n",
       "260        painfully     painfully           6        4.54          0.019901   \n",
       "122          parents        parent          26        3.43          0.017119   \n",
       "106           slowly        slowly          22        3.38          0.015272   \n",
       "827         saddened        sadden           1        5.97          0.014879   \n",
       "1218       complying        comply           9        4.05          0.014474   \n",
       "701            broom         broom           5        4.55          0.014114   \n",
       "234        disturbed       disturb           6        4.38          0.013745   \n",
       "1240       paragraph     paragraph          11        3.85          0.013663   \n",
       "44              legs           leg          21        3.32          0.013295   \n",
       "858         assailed        assail           1        5.91          0.012944   \n",
       "406       astonished    astonished           4        4.70          0.012737   \n",
       "203           hearer        hearer           1        5.90          0.012636   \n",
       "878         reproach      reproach           3        4.93          0.012247   \n",
       "1329      DISCLAIMER    disclaimer           4        4.67          0.011904   \n",
       "39            hardly        hardly          16        3.46          0.011746   \n",
       "5               copy          copy          24        3.24          0.011075   \n",
       "1262  redistributing  redistribute           2        5.22          0.010561   \n",
       "1146      rumination    rumination           1        5.82          0.010544   \n",
       "735     incarcerated   incarcerate           1        5.81          0.010272   \n",
       "143            chest         chest          14        3.50          0.009875   \n",
       "\n",
       "      cluster  \n",
       "1208        7  \n",
       "461         7  \n",
       "1297        7  \n",
       "780         6  \n",
       "10          9  \n",
       "656         6  \n",
       "1214        7  \n",
       "777         6  \n",
       "554         6  \n",
       "1238        7  \n",
       "260         4  \n",
       "122         1  \n",
       "106         6  \n",
       "827         4  \n",
       "1218        7  \n",
       "701         6  \n",
       "234         4  \n",
       "1240        9  \n",
       "44          6  \n",
       "858         4  \n",
       "406         4  \n",
       "203         4  \n",
       "878         4  \n",
       "1329        7  \n",
       "39          1  \n",
       "5           9  \n",
       "1262        7  \n",
       "1146        4  \n",
       "735         4  \n",
       "143         6  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['relativ freqency'], ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Translated</td>\n",
       "      <td>translate</td>\n",
       "      <td>3</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>events</td>\n",
       "      <td>event</td>\n",
       "      <td>1</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>normally</td>\n",
       "      <td>normally</td>\n",
       "      <td>3</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>write</td>\n",
       "      <td>write</td>\n",
       "      <td>8</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>reading</td>\n",
       "      <td>reading</td>\n",
       "      <td>1</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>recent</td>\n",
       "      <td>recent</td>\n",
       "      <td>1</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>wealth</td>\n",
       "      <td>wealth</td>\n",
       "      <td>1</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>arrange</td>\n",
       "      <td>arrange</td>\n",
       "      <td>3</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>ease</td>\n",
       "      <td>ease</td>\n",
       "      <td>1</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>frequently</td>\n",
       "      <td>frequently</td>\n",
       "      <td>2</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>opportunity</td>\n",
       "      <td>opportunity</td>\n",
       "      <td>4</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>subscribe</td>\n",
       "      <td>subscribe</td>\n",
       "      <td>1</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>possibilities</td>\n",
       "      <td>possibility</td>\n",
       "      <td>2</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>selection</td>\n",
       "      <td>selection</td>\n",
       "      <td>1</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>news</td>\n",
       "      <td>news</td>\n",
       "      <td>3</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>value</td>\n",
       "      <td>value</td>\n",
       "      <td>1</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>palely</td>\n",
       "      <td>palely</td>\n",
       "      <td>1</td>\n",
       "      <td>6.87</td>\n",
       "      <td>0.117933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>leading</td>\n",
       "      <td>lead</td>\n",
       "      <td>5</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>fully</td>\n",
       "      <td>fully</td>\n",
       "      <td>7</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>particular</td>\n",
       "      <td>particular</td>\n",
       "      <td>6</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>overview</td>\n",
       "      <td>overview</td>\n",
       "      <td>2</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>staff</td>\n",
       "      <td>staff</td>\n",
       "      <td>2</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>usually</td>\n",
       "      <td>usually</td>\n",
       "      <td>3</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>effects</td>\n",
       "      <td>effect</td>\n",
       "      <td>2</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>save</td>\n",
       "      <td>save</td>\n",
       "      <td>6</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>provide</td>\n",
       "      <td>provide</td>\n",
       "      <td>18</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>directly</td>\n",
       "      <td>directly</td>\n",
       "      <td>3</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>future</td>\n",
       "      <td>future</td>\n",
       "      <td>7</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>relatively</td>\n",
       "      <td>relatively</td>\n",
       "      <td>3</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>practice</td>\n",
       "      <td>practice</td>\n",
       "      <td>1</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>choice</td>\n",
       "      <td>choice</td>\n",
       "      <td>2</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>frequent</td>\n",
       "      <td>frequent</td>\n",
       "      <td>2</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>preparation</td>\n",
       "      <td>preparation</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>experience</td>\n",
       "      <td>experience</td>\n",
       "      <td>3</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>fast</td>\n",
       "      <td>fast</td>\n",
       "      <td>3</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>numerous</td>\n",
       "      <td>numerous</td>\n",
       "      <td>2</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>appropriate</td>\n",
       "      <td>appropriate</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>similar</td>\n",
       "      <td>similar</td>\n",
       "      <td>1</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>add</td>\n",
       "      <td>add</td>\n",
       "      <td>2</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>freely</td>\n",
       "      <td>freely</td>\n",
       "      <td>5</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>express</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>communication</td>\n",
       "      <td>communication</td>\n",
       "      <td>1</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>influence</td>\n",
       "      <td>influence</td>\n",
       "      <td>1</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>loss</td>\n",
       "      <td>loss</td>\n",
       "      <td>1</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>advantage</td>\n",
       "      <td>advantage</td>\n",
       "      <td>1</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>advice</td>\n",
       "      <td>advice</td>\n",
       "      <td>1</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>1</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>writing</td>\n",
       "      <td>writing</td>\n",
       "      <td>5</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>containing</td>\n",
       "      <td>contain</td>\n",
       "      <td>4</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              token          lemma  appearance  difficulty  relativ freqency  \\\n",
       "0        Translated      translate           3        4.03          0.001536   \n",
       "941          events          event           1        2.85          0.000011   \n",
       "959        normally       normally           3        3.40          0.000360   \n",
       "966           write          write           8        2.99          0.000999   \n",
       "967         reading        reading           1        2.92          0.000013   \n",
       "968          recent         recent           1        2.97          0.000015   \n",
       "972          wealth         wealth           1        3.48          0.000048   \n",
       "983         arrange        arrange           3        3.99          0.001405   \n",
       "990            ease           ease           1        3.66          0.000073   \n",
       "994      frequently     frequently           2        3.43          0.000171   \n",
       "1001    opportunity    opportunity           4        3.08          0.000306   \n",
       "1002           test           test           3        2.80          0.000091   \n",
       "2020      subscribe      subscribe           1        4.11          0.000205   \n",
       "1011  possibilities    possibility           2        3.34          0.000139   \n",
       "1014      selection      selection           1        3.37          0.000037   \n",
       "1067           news           news           3        2.59          0.000056   \n",
       "936           value          value           1        2.81          0.000010   \n",
       "931          palely         palely           1        6.87          0.117933   \n",
       "927         leading           lead           5        2.80          0.000252   \n",
       "924           fully          fully           7        3.14          0.001078   \n",
       "787      particular     particular           6        2.92          0.000478   \n",
       "788        overview       overview           2        3.87          0.000472   \n",
       "789           staff          staff           2        2.94          0.000055   \n",
       "800         usually        usually           3        2.84          0.000099   \n",
       "805         effects         effect           2        2.90          0.000051   \n",
       "822            save           save           6        2.91          0.000466   \n",
       "826         provide        provide          18        2.88          0.003908   \n",
       "1068       directly       directly           3        3.08          0.000172   \n",
       "827          future         future           7        2.67          0.000365   \n",
       "867      relatively     relatively           3        3.31          0.000292   \n",
       "885        practice       practice           1        2.93          0.000014   \n",
       "889          choice         choice           2        2.92          0.000053   \n",
       "892        frequent       frequent           2        3.70          0.000318   \n",
       "905     preparation    preparation           1        3.62          0.000066   \n",
       "907      experience     experience           3        2.71          0.000073   \n",
       "914            fast           fast           3        2.91          0.000116   \n",
       "840        numerous       numerous           2        3.30          0.000127   \n",
       "1070    appropriate    appropriate           1        3.29          0.000031   \n",
       "1083        similar        similar           1        2.77          0.000009   \n",
       "1086            add            add           2        2.93          0.000054   \n",
       "1219         freely         freely           5        3.89          0.003085   \n",
       "1226        express        express           1        3.32          0.000033   \n",
       "1246  communication  communication           1        3.31          0.000032   \n",
       "1253      influence      influence           1        3.18          0.000024   \n",
       "1255           loss           loss           1        2.95          0.000014   \n",
       "1256      advantage      advantage           1        3.21          0.000026   \n",
       "1260         advice         advice           1        3.12          0.000021   \n",
       "1216          adult          adult           1        3.24          0.000028   \n",
       "1271        writing        writing           5        2.94          0.000346   \n",
       "1285     containing        contain           4        3.43          0.000685   \n",
       "\n",
       "      cluster  \n",
       "0           0  \n",
       "941         0  \n",
       "959         0  \n",
       "966         0  \n",
       "967         0  \n",
       "968         0  \n",
       "972         0  \n",
       "983         0  \n",
       "990         0  \n",
       "994         0  \n",
       "1001        0  \n",
       "1002        0  \n",
       "2020        0  \n",
       "1011        0  \n",
       "1014        0  \n",
       "1067        0  \n",
       "936         0  \n",
       "931         0  \n",
       "927         0  \n",
       "924         0  \n",
       "787         0  \n",
       "788         0  \n",
       "789         0  \n",
       "800         0  \n",
       "805         0  \n",
       "822         0  \n",
       "826         0  \n",
       "1068        0  \n",
       "827         0  \n",
       "867         0  \n",
       "885         0  \n",
       "889         0  \n",
       "892         0  \n",
       "905         0  \n",
       "907         0  \n",
       "914         0  \n",
       "840         0  \n",
       "1070        0  \n",
       "1083        0  \n",
       "1086        0  \n",
       "1219        0  \n",
       "1226        0  \n",
       "1246        0  \n",
       "1253        0  \n",
       "1255        0  \n",
       "1256        0  \n",
       "1260        0  \n",
       "1216        0  \n",
       "1271        0  \n",
       "1285        0  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['cluster'], ascending=True).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 overall words\n",
      "34 words included\n",
      "24 words without duplicate included\n",
      "Keywords: 3\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Let's take a ride in my new car. I will drive you home in my car. I love cars, which drive very fast and loud. Trucks and vans are the best. You can also cook in the back of my car. Food, meals and drinks are very tasty. My mother is all in to cooking good meals, foods and healthy dishes. This keeps me healthy while. I love the pasta and pies she bakes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[8]._.is_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "words = [token.lemma_ for token in doc if token._.is_keyword]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cars</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.261916</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drive</td>\n",
       "      <td>drive</td>\n",
       "      <td>1</td>\n",
       "      <td>2.91</td>\n",
       "      <td>4.836455</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fast</td>\n",
       "      <td>fast</td>\n",
       "      <td>1</td>\n",
       "      <td>2.91</td>\n",
       "      <td>4.836455</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trucks</td>\n",
       "      <td>truck</td>\n",
       "      <td>1</td>\n",
       "      <td>3.45</td>\n",
       "      <td>16.757296</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vans</td>\n",
       "      <td>van</td>\n",
       "      <td>1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>9.427639</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>best</td>\n",
       "      <td>good</td>\n",
       "      <td>2</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.802679</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cooking</td>\n",
       "      <td>cook</td>\n",
       "      <td>1</td>\n",
       "      <td>3.37</td>\n",
       "      <td>13.931710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meals</td>\n",
       "      <td>meal</td>\n",
       "      <td>1</td>\n",
       "      <td>3.53</td>\n",
       "      <td>20.165559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>foods</td>\n",
       "      <td>food</td>\n",
       "      <td>1</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.261916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>2</td>\n",
       "      <td>3.22</td>\n",
       "      <td>39.461625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dishes</td>\n",
       "      <td>dish</td>\n",
       "      <td>1</td>\n",
       "      <td>3.84</td>\n",
       "      <td>41.026483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pasta</td>\n",
       "      <td>pasta</td>\n",
       "      <td>1</td>\n",
       "      <td>4.14</td>\n",
       "      <td>82.166298</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pies</td>\n",
       "      <td>pie</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>39.396291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bakes</td>\n",
       "      <td>bake</td>\n",
       "      <td>1</td>\n",
       "      <td>4.17</td>\n",
       "      <td>88.000591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token    lemma  appearance  difficulty  relativ freqency  cluster\n",
       "0      cars      car           1        2.58          2.261916        3\n",
       "1     drive    drive           1        2.91          4.836455        3\n",
       "2      fast     fast           1        2.91          4.836455        3\n",
       "3    Trucks    truck           1        3.45         16.757296        3\n",
       "4      vans      van           1        3.20          9.427639        3\n",
       "5      best     good           2        1.88          1.802679        3\n",
       "6   cooking     cook           1        3.37         13.931710        1\n",
       "7     meals     meal           1        3.53         20.165559        1\n",
       "8     foods     food           1        2.58          2.261916        1\n",
       "9   healthy  healthy           2        3.22         39.461625        1\n",
       "10   dishes     dish           1        3.84         41.026483        1\n",
       "11    pasta    pasta           1        4.14         82.166298        1\n",
       "12     pies      pie           1        3.82         39.396291        1\n",
       "13    bakes     bake           1        4.17         88.000591        1"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for token in doc:\n",
    "    if not token._.is_excluded:\n",
    "        data.append((token, token.lemma_, token._.appearance, token._.difficulty, token._.relativ_freq, token._.cluster))\n",
    "df = pd.DataFrame(data, columns=['token', 'lemma', 'appearance', 'difficulty', 'relativ freqency', 'cluster'])\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3, 3: 6, 1: 8, 2: 1})"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.cluster_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Deep learning (also known as deep structured learning) is part of a broader family \n",
    "of machine learning methods based on artificial neural networks with representation \n",
    "        learning. Learning can be supervised, semi-supervised or unsupervised.[1][2][3]Deep-learning \n",
    "        architectures such as deep neural networks, deep belief networks, recurrent neural networks \n",
    "        and convolutional neural networks have been applied to fields including computer vision, \n",
    "        machine vision, speech recognition, natural language processing, audio recognition, social \n",
    "        network filtering, machine translation, bioinformatics, drug design, medical image analysis, \n",
    "        material inspection and board game programs, where they have produced results comparable \n",
    "        to and in some cases surpassing human expert performance.[4][5][6]Artificial neural networks \n",
    "        (ANNs) were inspired by information processing and distributed communication nodes in biological \n",
    "        systems. ANNs have various differences from biological brains. Specifically, neural networks tend \n",
    "        to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) \n",
    "        and analogue.[7][8][9]The adjective \"deep\" in deep learning refers to the use of multiple layers in \n",
    "        the network. Early work showed that a linear perceptron cannot be a universal classifier, and then \n",
    "        that a network with a nonpolynomial activation function with one hidden layer of unbounded width \n",
    "        can on the other hand so be. Deep learning is a modern variation which is concerned with an unbounded\n",
    "        number of layers of bounded size, which permits practical application and optimized implementation, \n",
    "        while retaining theoretical universality under mild conditions. In deep learning the layers are \n",
    "        also permitted to be heterogeneous and to deviate widely from biologically informed connectionist \n",
    "        models, for the sake of efficiency, trainability and understandability, whence the \"structured\" part.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257 overall words\n",
      "156 words included\n",
      "114 words without duplicate included\n",
      "17 keywords found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-77-6e5208dea2dd>:19: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  kw_score = token.similarity(kw)\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3938454\n",
      "0.5744245\n",
      "0.33924755\n",
      "0.47624484\n",
      "0.43483993\n",
      "0.3270241\n",
      "1.0\n",
      "0.52090365\n",
      "0.4847936\n",
      "0.46523783\n",
      "0.49933636\n",
      "0.8762495\n",
      "0.44071323\n",
      "0.2955146\n",
      "0.25625694\n",
      "0.2955146\n",
      "0.5744245\n",
      "0.40140018\n",
      "0.5100599\n",
      "0.31690955\n",
      "0.22550173\n",
      "0.44786528\n",
      "0.38716203\n",
      "0.4775482\n",
      "0.53911096\n",
      "0.41549888\n",
      "0.4988885\n",
      "1.0\n",
      "0.5007288\n",
      "0.4610773\n",
      "1.0\n",
      "0.40415663\n",
      "0.5314103\n",
      "0.37051588\n",
      "0.40864474\n",
      "0.38324967\n",
      "0.48531094\n",
      "0.45266506\n",
      "0.38082403\n",
      "0.50242513\n",
      "1.0\n",
      "0.40681517\n",
      "0.31428733\n",
      "1.0\n",
      "0.43199307\n",
      "0.4897565\n",
      "1.0\n",
      "0.4878846\n",
      "0.36730403\n",
      "1.0\n",
      "0.59545803\n",
      "0.45384392\n",
      "0.36053327\n",
      "1.0\n",
      "0.46185136\n",
      "1.0\n",
      "0.43217084\n",
      "1.0\n",
      "0.52928066\n",
      "0.4549633\n",
      "0.3777898\n",
      "0.43885174\n",
      "0.35806483\n",
      "0.34795207\n",
      "0.43768883\n",
      "0.35460824\n",
      "0.6406614\n",
      "0.4451714\n",
      "0.47006604\n",
      "0.26633573\n",
      "0.36964554\n",
      "0.47620687\n",
      "0.45806268\n",
      "1.0\n",
      "0.3019013\n",
      "0.4692436\n",
      "0.44344023\n",
      "0.34928936\n",
      "1.0\n",
      "0.31417662\n",
      "0.0\n",
      "1.0\n",
      "0.48357797\n",
      "0.31554163\n",
      "1.0\n",
      "0.40788516\n",
      "0.48470917\n",
      "0.5270915\n",
      "0.38272974\n",
      "0.47252935\n",
      "0.50294\n",
      "0.49841097\n",
      "0.34320146\n",
      "0.44353783\n",
      "1.0\n",
      "0.5282285\n",
      "0.4437383\n",
      "0.45886028\n",
      "0.42962694\n",
      "0.59137577\n",
      "0.49776393\n",
      "0.23172696\n",
      "0.38636324\n",
      "0.4387642\n",
      "0.20261705\n",
      "0.3956485\n",
      "0.6638554\n",
      "0.51560885\n",
      "0.24427068\n",
      "0.34175387\n",
      "0.31902835\n",
      "0.42425045\n",
      "0.24197689\n",
      "0.21963838\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if not token._.is_excluded:\n",
    "        print(token._.keyword_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TextAnalytics2.2] *",
   "language": "python",
   "name": "conda-env-TextAnalytics2.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

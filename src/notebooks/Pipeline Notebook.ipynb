{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Project Pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Token\n",
    "from spacy.tokens import Doc\n",
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordfreq import zipf_frequency\n",
    "from wordfreq import word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "\n",
    "phoneme_dict = dict(cmudict.entries())\n",
    "\n",
    "def syllable_counter(word):\n",
    "    '''function that counts a syllable in a word'''\n",
    "    if word not in phoneme_dict:\n",
    "        return 0\n",
    "    syllables = phoneme_dict[word]\n",
    "    count = len([syllable for syllable in syllables if syllable[-1].isdigit()])\n",
    "    return round(count, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Minimum():\n",
    "    def __init__(self, initial_value):\n",
    "        self.value = initial_value\n",
    "    \n",
    "    def update_minimum(self, potential_min):\n",
    "        if potential_min < self.value:\n",
    "            self.value = potential_min\n",
    "            \n",
    "class Maximum():\n",
    "    def __init__(self, initial_value):\n",
    "        self.value = initial_value\n",
    "    \n",
    "    def update_maximum(self, potential_min):\n",
    "        if potential_min > self.value:\n",
    "            self.value = potential_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.0\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = '../data/kafka.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(open(text_file, \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcount(doc):\n",
    "    '''gives an overall word count'''\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            doc._.wordcount += 1\n",
    "    \n",
    "    print(f'{doc._.wordcount} words in document')\n",
    "         \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tokens(doc):\n",
    "    '''filters all tokens'''           \n",
    "    \n",
    "    \n",
    "    for token in doc:\n",
    "        # filter stopwords\n",
    "        if not token.is_alpha or token.is_stop:\n",
    "            token._.is_excluded = True\n",
    "            \n",
    "        # filter part-of-speech\n",
    "        elif token.pos_ not in ['NOUN', 'VERB', 'ADJ']:\n",
    "            token._.is_excluded = True\n",
    "            \n",
    "        # filter entities\n",
    "        elif token.ent_type != 0:\n",
    "                token._.is_excluded = True\n",
    "                \n",
    "        # count included words   \n",
    "        else:\n",
    "            doc._.included_wordcount += 1\n",
    "\n",
    "    print(f'{doc._.included_wordcount} words in vocabulary')\n",
    "         \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elim_dup(doc):\n",
    "    '''eliminates all duplicates and counts the appearance of the included words'''\n",
    "    already_appeared = {}\n",
    "\n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            if token.lemma_ in already_appeared.keys():\n",
    "                already_appeared[token.lemma_]._.appearance += 1\n",
    "                token._.is_excluded = True\n",
    "                doc._.included_wordcount -= 1\n",
    "            else:\n",
    "                token._.appearance = 1\n",
    "                already_appeared[token.lemma_] = token\n",
    "    \n",
    "    print(f'{doc._.included_wordcount} words in vocabulary without duplicates')\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Difficulty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syl_weight(n):\n",
    "    w = 0\n",
    "    for i in range(n):\n",
    "        w += 0.5**(i+1)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difficulty(doc):\n",
    "   \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            lemma = token.lemma_\n",
    "            difficulty = 8 - zipf_frequency(lemma, 'en') # score of 0-8\n",
    "            difficulty += syl_weight(syllable_counter(lemma)) # now score of 0-9\n",
    "            token._.difficulty = round(difficulty/9, 3) #normalised to 0-1\n",
    "            \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Freqency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relativ_freq(doc):\n",
    "    '''calculating the relativ frequency of a included word'''\n",
    "    \n",
    "    calculate_last = []\n",
    "    min_freq = Minimum(1)\n",
    "    max_score = Maximum(0)\n",
    "    \n",
    "    def calc_rel_freq(word_freq, token):\n",
    "        return round(((token._.appearance/doc._.wordcount) **2) / word_freq, 3)\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            overall_word_freq = word_frequency(token.lemma_, 'en')\n",
    "            \n",
    "            if overall_word_freq == 0:\n",
    "                calculate_last.append(token)\n",
    "            else:\n",
    "                min_freq.update_minimum(overall_word_freq)\n",
    "                token._.relativ_freq = calc_rel_freq(overall_word_freq, token)\n",
    "                max_score.update_maximum(token._.relativ_freq)\n",
    "    \n",
    "    for token in calculate_last:\n",
    "        token._.relativ_freq = calc_rel_freq(min_freq.value, token)\n",
    "        max_score.update_maximum(token._.relativ_freq)\n",
    "        \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            token._.relativ_freq /= max_score.value\n",
    "    \n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_keyphrases(doc):\n",
    "    \n",
    "    #TODO: was ist mit den fehlenden Wortvektoren\n",
    "    \n",
    "    kw = keywords(doc.text, split=True)\n",
    "    \n",
    "    keywords_token = []\n",
    "    already_in_list = []\n",
    "    for token in doc:\n",
    "        if token.text in kw:\n",
    "            token._.is_keyword = True\n",
    "            if token.text not in already_in_list:\n",
    "                keywords_token.append(token)\n",
    "                already_in_list.append(token.text)\n",
    "    doc._.keywords = keywords_token\n",
    "    \n",
    "    print(f'{len(keywords_token)} words are keywords')\n",
    "    \n",
    "    for token in doc:\n",
    "        for kw in keywords_token:\n",
    "            kw_score = token.similarity(kw)\n",
    "            if kw_score > token._.keyword_score:\n",
    "                token._.keyword_score =  kw_score\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline():\n",
    "    nlp = spacy.load('en_core_web_lg', disable = ['parser'])\n",
    "    \n",
    "    ## Preprocessing\n",
    "    # wordcount\n",
    "    Doc.set_extension('wordcount', default=0, force=True)\n",
    "    nlp.add_pipe(wordcount)\n",
    "    \n",
    "    # filter tokens\n",
    "    Doc.set_extension('included_wordcount', default=0, force=True)\n",
    "    Token.set_extension('is_excluded', default=False, force=True)\n",
    "    nlp.add_pipe(filter_tokens)\n",
    "    \n",
    "    # eliminate dublicates\n",
    "    Token.set_extension('appearance', default=np.nan, force=True)\n",
    "    nlp.add_pipe(elim_dup)\n",
    "    \n",
    "    \n",
    "    ## Word difficulty\n",
    "    # difficulty\n",
    "    Token.set_extension('difficulty', default=0, force=True)\n",
    "    nlp.add_pipe(get_difficulty)\n",
    "    \n",
    "    # relative frequency\n",
    "    Token.set_extension('relativ_freq', default=np.nan, force=True)\n",
    "    nlp.add_pipe(calculate_relativ_freq)\n",
    "    \n",
    "    \n",
    "    ## Word Relevance\n",
    "    # keywordscore\n",
    "    Doc.set_extension('keywords', default=[], force=True)\n",
    "    Token.set_extension('is_keyword', default=False, force=True)\n",
    "    Token.set_extension('keyword_score', default=0, force=True)\n",
    "    # nlp.add_pipe(check_keyphrases)\n",
    "    \n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger',\n",
       " 'ner',\n",
       " 'wordcount',\n",
       " 'filter_tokens',\n",
       " 'elim_dup',\n",
       " 'get_difficulty',\n",
       " 'calculate_relativ_freq']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = create_pipeline()\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_doc(doc):\n",
    "    data = []\n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            data.append((token, token.lemma_, token._.appearance, token._.difficulty, token._.relativ_freq, token._.keyword_score, token._.is_keyword))\n",
    "    df = pd.DataFrame(data, columns=['token', 'lemma', 'appearance', 'difficulty', 'relative freqency', 'keyword score', 'is keyword'])\n",
    "    \n",
    "    df[['difficulty_rank', 'keyword_rank']] = df[['difficulty', 'keyword score']].rank(ascending=False)\n",
    "    \n",
    "    df['overall_ranking'] = df['difficulty'] + df['relative freqency']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test scentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 words in document\n",
      "9 words in vocabulary\n",
      "6 words in vocabulary without duplicates\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Hi I'm a little little boy. Get me a piece of cake or I'll killed your mother. I am the mother of your mother\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_from_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>keyword score</th>\n",
       "      <th>is keyword</th>\n",
       "      <th>difficulty_rank</th>\n",
       "      <th>keyword_rank</th>\n",
       "      <th>overall_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cake</td>\n",
       "      <td>cake</td>\n",
       "      <td>1</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.788927</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>piece</td>\n",
       "      <td>piece</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.227465</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mother</td>\n",
       "      <td>mother</td>\n",
       "      <td>3</td>\n",
       "      <td>0.386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>killed</td>\n",
       "      <td>kill</td>\n",
       "      <td>1</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.172542</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy</td>\n",
       "      <td>boy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.134318</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.151052</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token   lemma  appearance  difficulty  relativ freqency  keyword score  \\\n",
       "3    cake    cake           1       0.452          0.788927              0   \n",
       "2   piece   piece           1       0.392          0.227465              0   \n",
       "5  mother  mother           3       0.386          1.000000              0   \n",
       "4  killed    kill           1       0.379          0.172542              0   \n",
       "1     boy     boy           1       0.367          0.134318              0   \n",
       "0  little  little           2       0.333          0.151052              0   \n",
       "\n",
       "   is keyword  difficulty_rank  keyword_rank  overall_ranking  \n",
       "3       False              1.0           3.5            0.452  \n",
       "2       False              2.0           3.5            0.392  \n",
       "5       False              3.0           3.5            0.386  \n",
       "4       False              4.0           3.5            0.379  \n",
       "1       False              5.0           3.5            0.367  \n",
       "0       False              6.0           3.5            0.333  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['overall_ranking'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25062 words in document\n",
      "7812 words in vocabulary\n",
      "1873 words in vocabulary without duplicates\n"
     ]
    }
   ],
   "source": [
    "with open(text_file, \"r\") as f:\n",
    "    doc = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_from_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relative freqency</th>\n",
       "      <th>keyword score</th>\n",
       "      <th>is keyword</th>\n",
       "      <th>difficulty_rank</th>\n",
       "      <th>keyword_rank</th>\n",
       "      <th>overall_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>charwoman</td>\n",
       "      <td>charwoman</td>\n",
       "      <td>8</td>\n",
       "      <td>0.807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>1.807000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>startlement</td>\n",
       "      <td>startlement</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.053115</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.942115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>teaboy</td>\n",
       "      <td>teaboy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.053115</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.942115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>fretsaw</td>\n",
       "      <td>fretsaw</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.053115</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.942115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>swinging</td>\n",
       "      <td>swinge</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.053115</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.942115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>soughing</td>\n",
       "      <td>soughing</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.053115</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.942115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>denuded</td>\n",
       "      <td>denude</td>\n",
       "      <td>1</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.037540</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.873540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>unenforceability</td>\n",
       "      <td>unenforceability</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.053115</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>11.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.822115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>entombed</td>\n",
       "      <td>entomb</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.817971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>glowering</td>\n",
       "      <td>glower</td>\n",
       "      <td>1</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.016374</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.812374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>timorous</td>\n",
       "      <td>timorous</td>\n",
       "      <td>1</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.009984</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.794984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>workshy</td>\n",
       "      <td>workshy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.036342</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>14.5</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.787342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>swang</td>\n",
       "      <td>swang</td>\n",
       "      <td>2</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.067093</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>34.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.780093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>windowpanes</td>\n",
       "      <td>windowpane</td>\n",
       "      <td>1</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>12.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.771390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>importune</td>\n",
       "      <td>importune</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>23.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.759958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>convulsive</td>\n",
       "      <td>convulsive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>13.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.759192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>untidiness</td>\n",
       "      <td>untidiness</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.025160</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>24.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.758160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>rumination</td>\n",
       "      <td>rumination</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>14.5</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.755393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>nonproprietary</td>\n",
       "      <td>nonproprietary</td>\n",
       "      <td>1</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.024361</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.755361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>enunciating</td>\n",
       "      <td>enunciate</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>16.5</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.753994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>incarcerated</td>\n",
       "      <td>incarcerate</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>16.5</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.753994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>saddened</td>\n",
       "      <td>sadden</td>\n",
       "      <td>1</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>18.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.752990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>perversity</td>\n",
       "      <td>perversity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>19.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.747594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>assailed</td>\n",
       "      <td>assail</td>\n",
       "      <td>1</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.745192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>hearer</td>\n",
       "      <td>hearer</td>\n",
       "      <td>1</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>21.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.744192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>snuffling</td>\n",
       "      <td>snuffle</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>28.5</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.743767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>unthinking</td>\n",
       "      <td>unthinking</td>\n",
       "      <td>1</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>22.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.738594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>forefinger</td>\n",
       "      <td>forefinger</td>\n",
       "      <td>1</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>26.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.728796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>footsteps</td>\n",
       "      <td>footstep</td>\n",
       "      <td>1</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>27.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.727594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>construed</td>\n",
       "      <td>construe</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>28.5</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.726594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>indemnify</td>\n",
       "      <td>indemnify</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>30.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.724396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>mealtime</td>\n",
       "      <td>mealtime</td>\n",
       "      <td>1</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>31.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.722195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>banister</td>\n",
       "      <td>banister</td>\n",
       "      <td>2</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.008786</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>35.5</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.720786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>gleeful</td>\n",
       "      <td>gleeful</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>32.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.720195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>unfastened</td>\n",
       "      <td>unfasten</td>\n",
       "      <td>1</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.013578</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>43.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.716578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>serviettes</td>\n",
       "      <td>serviette</td>\n",
       "      <td>1</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.013578</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>43.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.716578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>enveloped</td>\n",
       "      <td>envelop</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.716396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>unpleasantness</td>\n",
       "      <td>unpleasantness</td>\n",
       "      <td>1</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>35.5</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.713997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>resounding</td>\n",
       "      <td>resound</td>\n",
       "      <td>1</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>37.5</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.713796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>inedible</td>\n",
       "      <td>inedible</td>\n",
       "      <td>1</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>37.5</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.712997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>louts</td>\n",
       "      <td>lout</td>\n",
       "      <td>1</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>39.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.712792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>protruding</td>\n",
       "      <td>protrude</td>\n",
       "      <td>2</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.009585</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>46.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.711585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>unlink</td>\n",
       "      <td>unlink</td>\n",
       "      <td>1</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.012380</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>49.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.711380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>endearments</td>\n",
       "      <td>endearment</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>40.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.707997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>wracked</td>\n",
       "      <td>wrack</td>\n",
       "      <td>1</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>43.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.707393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>disclaim</td>\n",
       "      <td>disclaim</td>\n",
       "      <td>1</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>41.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.706396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>dampness</td>\n",
       "      <td>dampness</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>46.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.704396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>unimpeded</td>\n",
       "      <td>unimpeded</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>46.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.703597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>startled</td>\n",
       "      <td>startle</td>\n",
       "      <td>5</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.031550</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>84.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.703550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>gaslight</td>\n",
       "      <td>gaslight</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>48.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0.702396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 token             lemma  appearance  difficulty  \\\n",
       "1335         charwoman         charwoman           8       0.807   \n",
       "1166       startlement       startlement           1       0.889   \n",
       "1358            teaboy            teaboy           1       0.889   \n",
       "497            fretsaw           fretsaw           1       0.889   \n",
       "396           swinging            swinge           1       0.889   \n",
       "655           soughing          soughing           1       0.889   \n",
       "1181           denuded            denude           1       0.836   \n",
       "1804  unenforceability  unenforceability           1       0.769   \n",
       "1215          entombed            entomb           1       0.800   \n",
       "1194         glowering            glower           1       0.796   \n",
       "891           timorous          timorous           1       0.785   \n",
       "247            workshy           workshy           1       0.751   \n",
       "421              swang             swang           2       0.713   \n",
       "1399       windowpanes        windowpane           1       0.765   \n",
       "1322         importune         importune           1       0.734   \n",
       "1383        convulsive        convulsive           1       0.754   \n",
       "483         untidiness        untidiness           1       0.733   \n",
       "1552        rumination        rumination           1       0.751   \n",
       "1713    nonproprietary    nonproprietary           1       0.731   \n",
       "302        enunciating         enunciate           1       0.750   \n",
       "999       incarcerated       incarcerate           1       0.750   \n",
       "1128          saddened            sadden           1       0.747   \n",
       "1153        perversity        perversity           1       0.744   \n",
       "1172          assailed            assail           1       0.740   \n",
       "275             hearer            hearer           1       0.739   \n",
       "874          snuffling           snuffle           1       0.723   \n",
       "783         unthinking        unthinking           1       0.735   \n",
       "1485        forefinger        forefinger           1       0.726   \n",
       "474          footsteps          footstep           1       0.724   \n",
       "970          construed          construe           1       0.723   \n",
       "1807         indemnify         indemnify           1       0.722   \n",
       "976           mealtime          mealtime           1       0.719   \n",
       "765           banister          banister           2       0.712   \n",
       "1584           gleeful           gleeful           1       0.717   \n",
       "1274        unfastened          unfasten           1       0.703   \n",
       "1422        serviettes         serviette           1       0.703   \n",
       "381          enveloped           envelop           1       0.714   \n",
       "911     unpleasantness    unpleasantness           1       0.712   \n",
       "791         resounding           resound           1       0.711   \n",
       "935           inedible          inedible           1       0.711   \n",
       "445              louts              lout           1       0.708   \n",
       "737         protruding          protrude           2       0.702   \n",
       "1708            unlink            unlink           1       0.699   \n",
       "1325       endearments        endearment           1       0.706   \n",
       "1536           wracked             wrack           1       0.703   \n",
       "1776          disclaim          disclaim           1       0.704   \n",
       "1378          dampness          dampness           1       0.702   \n",
       "1142         unimpeded         unimpeded           1       0.702   \n",
       "952           startled           startle           5       0.672   \n",
       "894           gaslight          gaslight           1       0.700   \n",
       "\n",
       "      relative freqency  keyword score  is keyword  difficulty_rank  \\\n",
       "1335           1.000000              0       False              7.0   \n",
       "1166           0.053115              0       False              3.0   \n",
       "1358           0.053115              0       False              3.0   \n",
       "497            0.053115              0       False              3.0   \n",
       "396            0.053115              0       False              3.0   \n",
       "655            0.053115              0       False              3.0   \n",
       "1181           0.037540              0       False              6.0   \n",
       "1804           0.053115              0       False             11.0   \n",
       "1215           0.017971              0       False              8.0   \n",
       "1194           0.016374              0       False              9.0   \n",
       "891            0.009984              0       False             10.0   \n",
       "247            0.036342              0       False             14.5   \n",
       "421            0.067093              0       False             34.0   \n",
       "1399           0.006390              0       False             12.0   \n",
       "1322           0.025958              0       False             23.0   \n",
       "1383           0.005192              0       False             13.0   \n",
       "483            0.025160              0       False             24.0   \n",
       "1552           0.004393              0       False             14.5   \n",
       "1713           0.024361              0       False             25.0   \n",
       "302            0.003994              0       False             16.5   \n",
       "999            0.003994              0       False             16.5   \n",
       "1128           0.005990              0       False             18.0   \n",
       "1153           0.003594              0       False             19.0   \n",
       "1172           0.005192              0       False             20.0   \n",
       "275            0.005192              0       False             21.0   \n",
       "874            0.020767              0       False             28.5   \n",
       "783            0.003594              0       False             22.0   \n",
       "1485           0.002796              0       False             26.0   \n",
       "474            0.003594              0       False             27.0   \n",
       "970            0.003594              0       False             28.5   \n",
       "1807           0.002396              0       False             30.0   \n",
       "976            0.003195              0       False             31.0   \n",
       "765            0.008786              0       False             35.5   \n",
       "1584           0.003195              0       False             32.0   \n",
       "1274           0.013578              0       False             43.0   \n",
       "1422           0.013578              0       False             43.0   \n",
       "381            0.002396              0       False             33.0   \n",
       "911            0.001997              0       False             35.5   \n",
       "791            0.002796              0       False             37.5   \n",
       "935            0.001997              0       False             37.5   \n",
       "445            0.004792              0       False             39.0   \n",
       "737            0.009585              0       False             46.0   \n",
       "1708           0.012380              0       False             49.0   \n",
       "1325           0.001997              0       False             40.0   \n",
       "1536           0.004393              0       False             43.0   \n",
       "1776           0.002396              0       False             41.0   \n",
       "1378           0.002396              0       False             46.0   \n",
       "1142           0.001597              0       False             46.0   \n",
       "952            0.031550              0       False             84.0   \n",
       "894            0.002396              0       False             48.0   \n",
       "\n",
       "      keyword_rank  overall_ranking  \n",
       "1335         937.0         1.807000  \n",
       "1166         937.0         0.942115  \n",
       "1358         937.0         0.942115  \n",
       "497          937.0         0.942115  \n",
       "396          937.0         0.942115  \n",
       "655          937.0         0.942115  \n",
       "1181         937.0         0.873540  \n",
       "1804         937.0         0.822115  \n",
       "1215         937.0         0.817971  \n",
       "1194         937.0         0.812374  \n",
       "891          937.0         0.794984  \n",
       "247          937.0         0.787342  \n",
       "421          937.0         0.780093  \n",
       "1399         937.0         0.771390  \n",
       "1322         937.0         0.759958  \n",
       "1383         937.0         0.759192  \n",
       "483          937.0         0.758160  \n",
       "1552         937.0         0.755393  \n",
       "1713         937.0         0.755361  \n",
       "302          937.0         0.753994  \n",
       "999          937.0         0.753994  \n",
       "1128         937.0         0.752990  \n",
       "1153         937.0         0.747594  \n",
       "1172         937.0         0.745192  \n",
       "275          937.0         0.744192  \n",
       "874          937.0         0.743767  \n",
       "783          937.0         0.738594  \n",
       "1485         937.0         0.728796  \n",
       "474          937.0         0.727594  \n",
       "970          937.0         0.726594  \n",
       "1807         937.0         0.724396  \n",
       "976          937.0         0.722195  \n",
       "765          937.0         0.720786  \n",
       "1584         937.0         0.720195  \n",
       "1274         937.0         0.716578  \n",
       "1422         937.0         0.716578  \n",
       "381          937.0         0.716396  \n",
       "911          937.0         0.713997  \n",
       "791          937.0         0.713796  \n",
       "935          937.0         0.712997  \n",
       "445          937.0         0.712792  \n",
       "737          937.0         0.711585  \n",
       "1708         937.0         0.711380  \n",
       "1325         937.0         0.707997  \n",
       "1536         937.0         0.707393  \n",
       "1776         937.0         0.706396  \n",
       "1378         937.0         0.704396  \n",
       "1142         937.0         0.703597  \n",
       "952          937.0         0.703550  \n",
       "894          937.0         0.702396  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['overall_ranking'], ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 words in document\n",
      "32 words in vocabulary\n",
      "22 words in vocabulary without duplicates\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Let's take a ride in my new car. I will drive you home in my car. I love cars, which drive very fast and loud. Trucks and vans are the best. You can also cook in the back of my car. Food, meals and drinks are very tasty. My mother is all in to cooking good meals, foods and healthy dishes. This keeps me healthy while. I love the pasta and pies she bakes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_from_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relative freqency</th>\n",
       "      <th>keyword score</th>\n",
       "      <th>is keyword</th>\n",
       "      <th>difficulty_rank</th>\n",
       "      <th>keyword_rank</th>\n",
       "      <th>overall_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tasty</td>\n",
       "      <td>tasty</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.551000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bakes</td>\n",
       "      <td>bake</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.912728</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.431728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pasta</td>\n",
       "      <td>pasta</td>\n",
       "      <td>1</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.852215</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.395215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>meals</td>\n",
       "      <td>meal</td>\n",
       "      <td>2</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.836605</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.284605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cook</td>\n",
       "      <td>cook</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.577998</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.007998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dishes</td>\n",
       "      <td>dish</td>\n",
       "      <td>1</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.425516</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.907516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pies</td>\n",
       "      <td>pie</td>\n",
       "      <td>1</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.408622</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.888622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.409298</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.850298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>car</td>\n",
       "      <td>car</td>\n",
       "      <td>4</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.375376</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>16.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.717376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>loud</td>\n",
       "      <td>loud</td>\n",
       "      <td>1</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.190425</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.633425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trucks</td>\n",
       "      <td>truck</td>\n",
       "      <td>1</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.173801</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.612801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drive</td>\n",
       "      <td>drive</td>\n",
       "      <td>2</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.200662</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.579662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vans</td>\n",
       "      <td>van</td>\n",
       "      <td>1</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.097780</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.508780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ride</td>\n",
       "      <td>ride</td>\n",
       "      <td>1</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.097780</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.508780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>drinks</td>\n",
       "      <td>drink</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.074163</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.472163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Food</td>\n",
       "      <td>food</td>\n",
       "      <td>2</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.093827</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>16.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.435827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mother</td>\n",
       "      <td>mother</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.032301</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.418301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>love</td>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.040916</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.342916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let</td>\n",
       "      <td>let</td>\n",
       "      <td>1</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.015846</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.338846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>keeps</td>\n",
       "      <td>keep</td>\n",
       "      <td>1</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.334799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>best</td>\n",
       "      <td>good</td>\n",
       "      <td>2</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.282684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.253480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token    lemma  appearance  difficulty  relative freqency  \\\n",
       "14    tasty    tasty           1       0.551           1.000000   \n",
       "21    bakes     bake           1       0.519           0.912728   \n",
       "19    pasta    pasta           1       0.543           0.852215   \n",
       "12    meals     meal           2       0.448           0.836605   \n",
       "10     cook     cook           2       0.430           0.577998   \n",
       "17   dishes     dish           1       0.482           0.425516   \n",
       "20     pies      pie           1       0.480           0.408622   \n",
       "16  healthy  healthy           2       0.441           0.409298   \n",
       "3       car      car           4       0.342           0.375376   \n",
       "6      loud     loud           1       0.443           0.190425   \n",
       "7    Trucks    truck           1       0.439           0.173801   \n",
       "4     drive    drive           2       0.379           0.200662   \n",
       "8      vans      van           1       0.411           0.097780   \n",
       "1      ride     ride           1       0.411           0.097780   \n",
       "13   drinks    drink           1       0.398           0.074163   \n",
       "11     Food     food           2       0.342           0.093827   \n",
       "15   mother   mother           1       0.386           0.032301   \n",
       "5      love     love           2       0.302           0.040916   \n",
       "0       Let      let           1       0.323           0.015846   \n",
       "18    keeps     keep           1       0.320           0.014799   \n",
       "9      best     good           2       0.264           0.018684   \n",
       "2       new      new           1       0.250           0.003480   \n",
       "\n",
       "    keyword score  is keyword  difficulty_rank  keyword_rank  overall_ranking  \n",
       "14              0       False              1.0          11.5         1.551000  \n",
       "21              0       False              3.0          11.5         1.431728  \n",
       "19              0       False              2.0          11.5         1.395215  \n",
       "12              0       False              6.0          11.5         1.284605  \n",
       "10              0       False             10.0          11.5         1.007998  \n",
       "17              0       False              4.0          11.5         0.907516  \n",
       "20              0       False              5.0          11.5         0.888622  \n",
       "16              0       False              8.0          11.5         0.850298  \n",
       "3               0       False             16.5          11.5         0.717376  \n",
       "6               0       False              7.0          11.5         0.633425  \n",
       "7               0       False              9.0          11.5         0.612801  \n",
       "4               0       False             15.0          11.5         0.579662  \n",
       "8               0       False             11.5          11.5         0.508780  \n",
       "1               0       False             11.5          11.5         0.508780  \n",
       "13              0       False             13.0          11.5         0.472163  \n",
       "11              0       False             16.5          11.5         0.435827  \n",
       "15              0       False             14.0          11.5         0.418301  \n",
       "5               0       False             20.0          11.5         0.342916  \n",
       "0               0       False             18.0          11.5         0.338846  \n",
       "18              0       False             19.0          11.5         0.334799  \n",
       "9               0       False             21.0          11.5         0.282684  \n",
       "2               0       False             22.0          11.5         0.253480  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['overall_ranking'], ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Deep learning (also known as deep structured learning) is part of a broader family \n",
    "of machine learning methods based on artificial neural networks with representation \n",
    "        learning. Learning can be supervised, semi-supervised or unsupervised.[1][2][3]Deep-learning \n",
    "        architectures such as deep neural networks, deep belief networks, recurrent neural networks \n",
    "        and convolutional neural networks have been applied to fields including computer vision, \n",
    "        machine vision, speech recognition, natural language processing, audio recognition, social \n",
    "        network filtering, machine translation, bioinformatics, drug design, medical image analysis, \n",
    "        material inspection and board game programs, where they have produced results comparable \n",
    "        to and in some cases surpassing human expert performance.[4][5][6]Artificial neural networks \n",
    "        (ANNs) were inspired by information processing and distributed communication nodes in biological \n",
    "        systems. ANNs have various differences from biological brains. Specifically, neural networks tend \n",
    "        to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) \n",
    "        and analogue.[7][8][9]The adjective \"deep\" in deep learning refers to the use of multiple layers in \n",
    "        the network. Early work showed that a linear perceptron cannot be a universal classifier, and then \n",
    "        that a network with a nonpolynomial activation function with one hidden layer of unbounded width \n",
    "        can on the other hand so be. Deep learning is a modern variation which is concerned with an unbounded\n",
    "        number of layers of bounded size, which permits practical application and optimized implementation, \n",
    "        while retaining theoretical universality under mild conditions. In deep learning the layers are \n",
    "        also permitted to be heterogeneous and to deviate widely from biologically informed connectionist \n",
    "        models, for the sake of efficiency, trainability and understandability, whence the \"structured\" part.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257 words in document\n",
      "152 words in vocabulary\n",
      "110 words in vocabulary without duplicates\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_from_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relative freqency</th>\n",
       "      <th>keyword score</th>\n",
       "      <th>is keyword</th>\n",
       "      <th>difficulty_rank</th>\n",
       "      <th>keyword_rank</th>\n",
       "      <th>overall_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>nonpolynomial</td>\n",
       "      <td>nonpolynomial</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>1.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>bioinformatics</td>\n",
       "      <td>bioinformatic</td>\n",
       "      <td>1</td>\n",
       "      <td>0.738</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>1.738000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>trainability</td>\n",
       "      <td>trainability</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.934694</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>1.668694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>connectionist</td>\n",
       "      <td>connectionist</td>\n",
       "      <td>1</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.741101</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>1.464101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>understandability</td>\n",
       "      <td>understandability</td>\n",
       "      <td>1</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.724685</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>1.446685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>convolutional</td>\n",
       "      <td>convolutional</td>\n",
       "      <td>1</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.489316</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>1.192316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>unbounded</td>\n",
       "      <td>unbounded</td>\n",
       "      <td>2</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.270206</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.975206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>neural</td>\n",
       "      <td>neural</td>\n",
       "      <td>6</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.197697</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>21.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.767697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>classifier</td>\n",
       "      <td>classifier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.107009</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>11.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.737009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>universality</td>\n",
       "      <td>universality</td>\n",
       "      <td>1</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.703168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>heterogeneous</td>\n",
       "      <td>heterogeneous</td>\n",
       "      <td>1</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.020818</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.679818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>deviate</td>\n",
       "      <td>deviate</td>\n",
       "      <td>1</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.017752</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.658752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>adjective</td>\n",
       "      <td>adjective</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.011450</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>12.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.630450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>optimized</td>\n",
       "      <td>optimize</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.011450</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>12.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.630450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>recurrent</td>\n",
       "      <td>recurrent</td>\n",
       "      <td>1</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>14.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.621786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>supervised</td>\n",
       "      <td>supervise</td>\n",
       "      <td>1</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>14.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.621786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>surpassing</td>\n",
       "      <td>surpass</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.011450</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.617450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>filtering</td>\n",
       "      <td>filtering</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>17.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.600755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>supervised</td>\n",
       "      <td>supervised</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>18.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.587241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>activation</td>\n",
       "      <td>activation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>19.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.580075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>organisms</td>\n",
       "      <td>organism</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.578982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>distributed</td>\n",
       "      <td>distribute</td>\n",
       "      <td>1</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>22.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.568712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>structured</td>\n",
       "      <td>structured</td>\n",
       "      <td>2</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.012652</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.555652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>symbolic</td>\n",
       "      <td>symbolic</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.553753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>theoretical</td>\n",
       "      <td>theoretical</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>24.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.550081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>variation</td>\n",
       "      <td>variation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>26.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.537776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>inspired</td>\n",
       "      <td>inspire</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>27.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.536629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>nodes</td>\n",
       "      <td>node</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>29.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.536463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>linear</td>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>27.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.535957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>inspection</td>\n",
       "      <td>inspection</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>30.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.529735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>comparable</td>\n",
       "      <td>comparable</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>30.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.529735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>artificial</td>\n",
       "      <td>artificial</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>32.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.527449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>implementation</td>\n",
       "      <td>implementation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.523231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>static</td>\n",
       "      <td>static</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>34.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.521957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>biological</td>\n",
       "      <td>biological</td>\n",
       "      <td>3</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>36.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>informed</td>\n",
       "      <td>inform</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.515735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>retaining</td>\n",
       "      <td>retain</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>37.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.509517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>representation</td>\n",
       "      <td>representation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>37.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.508912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>dynamic</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>1</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>39.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.508122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>layers</td>\n",
       "      <td>layer</td>\n",
       "      <td>4</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.017122</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>46.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.508122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>efficiency</td>\n",
       "      <td>efficiency</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.506954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>architectures</td>\n",
       "      <td>architecture</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>41.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.502871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>permits</td>\n",
       "      <td>permit</td>\n",
       "      <td>2</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.500698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>width</td>\n",
       "      <td>width</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>42.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.499140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>processing</td>\n",
       "      <td>processing</td>\n",
       "      <td>2</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>44.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.497405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>mild</td>\n",
       "      <td>mild</td>\n",
       "      <td>1</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>46.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.492909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>translation</td>\n",
       "      <td>translation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>45.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.492812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>recognition</td>\n",
       "      <td>recognition</td>\n",
       "      <td>2</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>48.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.492701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>universal</td>\n",
       "      <td>universal</td>\n",
       "      <td>1</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>49.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.489659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>audio</td>\n",
       "      <td>audio</td>\n",
       "      <td>1</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>50.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.487741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 token              lemma  appearance  difficulty  \\\n",
       "78       nonpolynomial      nonpolynomial           1       0.889   \n",
       "33      bioinformatics      bioinformatic           1       0.738   \n",
       "108       trainability       trainability           1       0.734   \n",
       "104      connectionist      connectionist           1       0.723   \n",
       "109  understandability  understandability           1       0.722   \n",
       "19       convolutional      convolutional           1       0.703   \n",
       "82           unbounded          unbounded           2       0.705   \n",
       "10              neural             neural           6       0.570   \n",
       "77          classifier         classifier           1       0.630   \n",
       "98        universality       universality           1       0.675   \n",
       "101      heterogeneous      heterogeneous           1       0.659   \n",
       "102            deviate            deviate           1       0.641   \n",
       "67           adjective          adjective           1       0.619   \n",
       "94           optimized           optimize           1       0.619   \n",
       "18           recurrent          recurrent           1       0.612   \n",
       "13          supervised          supervise           1       0.612   \n",
       "48          surpassing            surpass           1       0.606   \n",
       "31           filtering          filtering           1       0.594   \n",
       "14          supervised         supervised           1       0.582   \n",
       "79          activation         activation           1       0.576   \n",
       "64           organisms           organism           1       0.575   \n",
       "53         distributed         distribute           1       0.565   \n",
       "3           structured         structured           2       0.543   \n",
       "62            symbolic           symbolic           1       0.551   \n",
       "97         theoretical        theoretical           1       0.548   \n",
       "86           variation          variation           1       0.536   \n",
       "51            inspired            inspire           1       0.534   \n",
       "55               nodes               node           1       0.532   \n",
       "75              linear             linear           1       0.534   \n",
       "40          inspection         inspection           1       0.528   \n",
       "46          comparable         comparable           1       0.528   \n",
       "9           artificial         artificial           1       0.526   \n",
       "95      implementation     implementation           1       0.522   \n",
       "61              static             static           1       0.520   \n",
       "56          biological         biological           3       0.512   \n",
       "103           informed             inform           1       0.514   \n",
       "96           retaining             retain           1       0.508   \n",
       "12      representation     representation           1       0.508   \n",
       "65             dynamic            dynamic           1       0.507   \n",
       "71              layers              layer           4       0.491   \n",
       "107         efficiency         efficiency           1       0.506   \n",
       "16       architectures       architecture           1       0.502   \n",
       "91             permits             permit           2       0.496   \n",
       "83               width              width           1       0.497   \n",
       "29          processing         processing           2       0.494   \n",
       "99                mild               mild           1       0.491   \n",
       "32         translation        translation           1       0.492   \n",
       "26         recognition        recognition           2       0.490   \n",
       "76           universal          universal           1       0.489   \n",
       "30               audio              audio           1       0.487   \n",
       "\n",
       "     relative freqency  keyword score  is keyword  difficulty_rank  \\\n",
       "78            1.000000              0       False              1.0   \n",
       "33            1.000000              0       False              2.0   \n",
       "108           0.934694              0       False              3.0   \n",
       "104           0.741101              0       False              4.0   \n",
       "109           0.724685              0       False              5.0   \n",
       "19            0.489316              0       False              7.0   \n",
       "82            0.270206              0       False              6.0   \n",
       "10            0.197697              0       False             21.0   \n",
       "77            0.107009              0       False             11.0   \n",
       "98            0.028168              0       False              8.0   \n",
       "101           0.020818              0       False              9.0   \n",
       "102           0.017752              0       False             10.0   \n",
       "67            0.011450              0       False             12.5   \n",
       "94            0.011450              0       False             12.5   \n",
       "18            0.009786              0       False             14.5   \n",
       "13            0.009786              0       False             14.5   \n",
       "48            0.011450              0       False             16.0   \n",
       "31            0.006755              0       False             17.0   \n",
       "14            0.005241              0       False             18.0   \n",
       "79            0.004075              0       False             19.0   \n",
       "64            0.003982              0       False             20.0   \n",
       "53            0.003712              0       False             22.0   \n",
       "3             0.012652              0       False             25.0   \n",
       "62            0.002753              0       False             23.0   \n",
       "97            0.002081              0       False             24.0   \n",
       "86            0.001776              0       False             26.0   \n",
       "51            0.002629              0       False             27.5   \n",
       "55            0.004463              0       False             29.0   \n",
       "75            0.001957              0       False             27.5   \n",
       "40            0.001735              0       False             30.5   \n",
       "46            0.001735              0       False             30.5   \n",
       "9             0.001449              0       False             32.0   \n",
       "95            0.001231              0       False             33.0   \n",
       "61            0.001957              0       False             34.0   \n",
       "56            0.009000              0       False             36.0   \n",
       "103           0.001735              0       False             35.0   \n",
       "96            0.001517              0       False             37.5   \n",
       "12            0.000912              0       False             37.5   \n",
       "65            0.001122              0       False             39.0   \n",
       "71            0.017122              0       False             46.5   \n",
       "107           0.000954              0       False             40.0   \n",
       "16            0.000871              0       False             41.0   \n",
       "91            0.004698              0       False             43.0   \n",
       "83            0.002140              0       False             42.0   \n",
       "29            0.003405              0       False             44.0   \n",
       "99            0.001909              0       False             46.5   \n",
       "32            0.000812              0       False             45.0   \n",
       "26            0.002701              0       False             48.0   \n",
       "76            0.000659              0       False             49.0   \n",
       "30            0.000741              0       False             50.0   \n",
       "\n",
       "     keyword_rank  overall_ranking  \n",
       "78           55.5         1.889000  \n",
       "33           55.5         1.738000  \n",
       "108          55.5         1.668694  \n",
       "104          55.5         1.464101  \n",
       "109          55.5         1.446685  \n",
       "19           55.5         1.192316  \n",
       "82           55.5         0.975206  \n",
       "10           55.5         0.767697  \n",
       "77           55.5         0.737009  \n",
       "98           55.5         0.703168  \n",
       "101          55.5         0.679818  \n",
       "102          55.5         0.658752  \n",
       "67           55.5         0.630450  \n",
       "94           55.5         0.630450  \n",
       "18           55.5         0.621786  \n",
       "13           55.5         0.621786  \n",
       "48           55.5         0.617450  \n",
       "31           55.5         0.600755  \n",
       "14           55.5         0.587241  \n",
       "79           55.5         0.580075  \n",
       "64           55.5         0.578982  \n",
       "53           55.5         0.568712  \n",
       "3            55.5         0.555652  \n",
       "62           55.5         0.553753  \n",
       "97           55.5         0.550081  \n",
       "86           55.5         0.537776  \n",
       "51           55.5         0.536629  \n",
       "55           55.5         0.536463  \n",
       "75           55.5         0.535957  \n",
       "40           55.5         0.529735  \n",
       "46           55.5         0.529735  \n",
       "9            55.5         0.527449  \n",
       "95           55.5         0.523231  \n",
       "61           55.5         0.521957  \n",
       "56           55.5         0.521000  \n",
       "103          55.5         0.515735  \n",
       "96           55.5         0.509517  \n",
       "12           55.5         0.508912  \n",
       "65           55.5         0.508122  \n",
       "71           55.5         0.508122  \n",
       "107          55.5         0.506954  \n",
       "16           55.5         0.502871  \n",
       "91           55.5         0.500698  \n",
       "83           55.5         0.499140  \n",
       "29           55.5         0.497405  \n",
       "99           55.5         0.492909  \n",
       "32           55.5         0.492812  \n",
       "26           55.5         0.492701  \n",
       "76           55.5         0.489659  \n",
       "30           55.5         0.487741  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['overall_ranking'], ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TextAnalytics2.2] *",
   "language": "python",
   "name": "conda-env-TextAnalytics2.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

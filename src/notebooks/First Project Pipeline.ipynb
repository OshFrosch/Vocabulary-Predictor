{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Project Pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Token\n",
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordfreq import zipf_frequency\n",
    "from wordfreq import word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "\n",
    "phoneme_dict = dict(cmudict.entries())\n",
    "\n",
    "def syllable_counter(word):\n",
    "    '''function that counts a syllable in a word'''\n",
    "    if word not in phoneme_dict:\n",
    "        return 0\n",
    "    syllables = phoneme_dict[word]\n",
    "    count = len([syllable for syllable in syllables if syllable[-1].isdigit()])\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = '../data/kafka.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(open(text_file, \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg', disable = ['parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'ner']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc.set_extension('wordcount', default=0, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcount(doc):\n",
    "    '''gives an overall word count'''\n",
    "    wordcount = 0\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            wordcount += 1\n",
    "            \n",
    "    doc._.wordcount = wordcount\n",
    "    \n",
    "    print(f'{wordcount} overall words')\n",
    "         \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'ner', 'wordcount']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(wordcount)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension('is_excluded', default=False, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tokens(doc):\n",
    "    '''filters all tokens'''           \n",
    "    \n",
    "    for token in doc:\n",
    "        # filter stopwords\n",
    "        if not token.is_alpha or token.is_stop:\n",
    "            token._.is_excluded = True\n",
    "        # filter part-of-speech\n",
    "        elif token.pos_ not in ['NOUN', 'VERB', 'ADJ', 'ADV']: # ADV?\n",
    "            token._.is_excluded = True\n",
    "        # filter entities\n",
    "        elif token.ent_type != 0:\n",
    "                token._.is_excluded = True\n",
    "         \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(doc):\n",
    "    c = 0\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            c += 1\n",
    "    print(f'{c} words included')\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'ner', 'wordcount', 'filter_tokens', 'count_words']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(filter_tokens)\n",
    "nlp.add_pipe(count_words)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension('appearance', default=np.nan, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elim_dup(doc):\n",
    "    '''eliminates all duplicates and counts the appearance of the included words'''\n",
    "    already_appeared = {}\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            if token.lemma_ in already_appeared.keys():\n",
    "                already_appeared[token.lemma_] += 1\n",
    "                token._.is_excluded = True\n",
    "            else: \n",
    "                already_appeared[token.lemma_] = 1\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            token._.appearance = already_appeared[token.lemma_]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_voc(doc):\n",
    "    c = 0\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            c += 1\n",
    "    print(f'{c} words without duplicate included')\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger',\n",
       " 'ner',\n",
       " 'wordcount',\n",
       " 'filter_tokens',\n",
       " 'count_words',\n",
       " 'elim_dup',\n",
       " 'count_voc']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(elim_dup)\n",
    "nlp.add_pipe(count_voc)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Freqency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension('relativ_freq', default=np.nan, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relativ_freq(doc):\n",
    "    '''calculating the relativ frequency of a included word'''\n",
    "    \n",
    "    maw = 20 # maximal appearance weight\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            text_freq = min(maw, token._.appearance) / doc._.wordcount\n",
    "            overall_freq = word_frequency(token.lemma_, 'en')\n",
    "            if overall_freq != 0:\n",
    "                token._.relativ_freq = text_freq**2 / overall_freq\n",
    "        \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger',\n",
       " 'ner',\n",
       " 'wordcount',\n",
       " 'filter_tokens',\n",
       " 'count_words',\n",
       " 'elim_dup',\n",
       " 'count_voc',\n",
       " 'calculate_relativ_freq']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(calculate_relativ_freq)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension('difficulty', default=0, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difficulty(doc):\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            lemma = token.lemma_\n",
    "            readability = zipf_frequency(lemma, 'en') # score of 1-8\n",
    "            syl = syllable_counter(lemma)\n",
    "            if syl > 1 and readability != 0 :\n",
    "                readability -= 0 #(syl - 2)/2\n",
    "            token._.difficulty = round(8 - readability, 2)\n",
    "            \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger',\n",
       " 'ner',\n",
       " 'wordcount',\n",
       " 'filter_tokens',\n",
       " 'count_words',\n",
       " 'elim_dup',\n",
       " 'count_voc',\n",
       " 'calculate_relativ_freq',\n",
       " 'get_difficulty']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(get_difficulty)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension('cluster', default=np.nan, force=True)\n",
    "Doc.set_extension('cluster_sizes', default=0, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_words(doc):\n",
    "    \n",
    "    X = [tok.vector for tok in doc if not tok._.is_excluded]\n",
    "    dist = nltk.cluster.util.cosine_distance\n",
    "    k = int(round(np.log(doc._.wordcount), 0 )) #prototype\n",
    "    print(k)\n",
    "    \n",
    "    kclusterer = nltk.cluster.KMeansClusterer(k, distance=dist)\n",
    "    assigned_clusters = kclusterer.cluster(X, assign_clusters=True)\n",
    "    clusters = iter(assigned_clusters)\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            token._.cluster = next(clusters)\n",
    "    \n",
    "    doc._.cluster_sizes = collections.Counter(assigned_clusters)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_smallest_clusters(doc):\n",
    "    \n",
    "    cluster_count = len(doc._.cluster_sizes)\n",
    "    smallest_clusters = []\n",
    "    for i in range(int(cluster_count * 2/3), cluster_count):\n",
    "        c = doc._.cluster_sizes.most_common()[i][0]\n",
    "        smallest_clusters.append(c)\n",
    "        \n",
    "    print(smallest_clusters)\n",
    "        \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            if token._.cluster in smallest_clusters:\n",
    "                token._.is_excluded = True\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger',\n",
       " 'ner',\n",
       " 'wordcount',\n",
       " 'filter_tokens',\n",
       " 'count_words',\n",
       " 'elim_dup',\n",
       " 'count_voc',\n",
       " 'calculate_relativ_freq',\n",
       " 'get_difficulty',\n",
       " 'cluster_words',\n",
       " 'exclude_smallest_clusters']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(cluster_words)\n",
    "nlp.add_pipe(exclude_smallest_clusters)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test scentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 overall words\n",
      "9 words included\n",
      "6 words without duplicate included\n",
      "3\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Hi I'm a little little boy. Get me a piece of cake or I'll killed your mother. I am the mother of your mother\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3, 0: 2, 2: 1})"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.cluster_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>2</td>\n",
       "      <td>2.25</td>\n",
       "      <td>12.356663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy</td>\n",
       "      <td>boy</td>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>10.988045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>piece</td>\n",
       "      <td>piece</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>18.607836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cake</td>\n",
       "      <td>cake</td>\n",
       "      <td>1</td>\n",
       "      <td>3.57</td>\n",
       "      <td>64.539447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mother</td>\n",
       "      <td>mother</td>\n",
       "      <td>3</td>\n",
       "      <td>2.72</td>\n",
       "      <td>81.806283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token   lemma  appearance  difficulty  relativ freqency  cluster\n",
       "0  little  little           2        2.25         12.356663        1\n",
       "1     boy     boy           1        2.80         10.988045        1\n",
       "2   piece   piece           1        3.03         18.607836        0\n",
       "3    cake    cake           1        3.57         64.539447        0\n",
       "4  mother  mother           3        2.72         81.806283        1"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for token in doc:\n",
    "    if not token._.is_excluded:\n",
    "        data.append((token, token.lemma_, token._.appearance, token._.difficulty, token._.relativ_freq, token._.cluster))\n",
    "df = pd.DataFrame(data, columns=['token', 'lemma', 'appearance', 'difficulty', 'relativ freqency', 'cluster'])\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cake</td>\n",
       "      <td>cake</td>\n",
       "      <td>1</td>\n",
       "      <td>3.57</td>\n",
       "      <td>64.539447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>piece</td>\n",
       "      <td>piece</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>18.607836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy</td>\n",
       "      <td>boy</td>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>10.988045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mother</td>\n",
       "      <td>mother</td>\n",
       "      <td>3</td>\n",
       "      <td>2.72</td>\n",
       "      <td>81.806283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>2</td>\n",
       "      <td>2.25</td>\n",
       "      <td>12.356663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token   lemma  appearance  difficulty  relativ freqency  cluster\n",
       "3    cake    cake           1        3.57         64.539447        0\n",
       "2   piece   piece           1        3.03         18.607836        0\n",
       "1     boy     boy           1        2.80         10.988045        1\n",
       "4  mother  mother           3        2.72         81.806283        1\n",
       "0  little  little           2        2.25         12.356663        1"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['difficulty'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mother</td>\n",
       "      <td>mother</td>\n",
       "      <td>3</td>\n",
       "      <td>2.72</td>\n",
       "      <td>81.806283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cake</td>\n",
       "      <td>cake</td>\n",
       "      <td>1</td>\n",
       "      <td>3.57</td>\n",
       "      <td>64.539447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>piece</td>\n",
       "      <td>piece</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>18.607836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>2</td>\n",
       "      <td>2.25</td>\n",
       "      <td>12.356663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy</td>\n",
       "      <td>boy</td>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>10.988045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token   lemma  appearance  difficulty  relativ freqency  cluster\n",
       "4  mother  mother           3        2.72         81.806283        1\n",
       "3    cake    cake           1        3.57         64.539447        0\n",
       "2   piece   piece           1        3.03         18.607836        0\n",
       "0  little  little           2        2.25         12.356663        1\n",
       "1     boy     boy           1        2.80         10.988045        1"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['relativ freqency'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25062 overall words\n",
      "8511 words included\n",
      "2039 words without duplicate included\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuakraft/opt/anaconda3/envs/TextAnalytics/lib/python3.8/site-packages/nltk/cluster/util.py:131: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return 1 - (numpy.dot(u, v) / (sqrt(numpy.dot(u, u)) * sqrt(numpy.dot(v, v))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 7, 0]\n"
     ]
    }
   ],
   "source": [
    "with open(text_file, \"r\") as f:\n",
    "    doc = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 255,\n",
       "         0: 225,\n",
       "         7: 340,\n",
       "         4: 245,\n",
       "         8: 162,\n",
       "         1: 268,\n",
       "         2: 158,\n",
       "         5: 120,\n",
       "         3: 176,\n",
       "         9: 73})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.cluster_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Translated</td>\n",
       "      <td>translate</td>\n",
       "      <td>3</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>21</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cost</td>\n",
       "      <td>cost</td>\n",
       "      <td>6</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>restrictions</td>\n",
       "      <td>restriction</td>\n",
       "      <td>2</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whatsoever</td>\n",
       "      <td>whatsoever</td>\n",
       "      <td>3</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>worries</td>\n",
       "      <td>worry</td>\n",
       "      <td>6</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>making</td>\n",
       "      <td>make</td>\n",
       "      <td>14</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>connections</td>\n",
       "      <td>connection</td>\n",
       "      <td>2</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>4</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>irregular</td>\n",
       "      <td>irregular</td>\n",
       "      <td>1</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           token        lemma  appearance  difficulty  relativ freqency  \\\n",
       "0     Translated    translate           3        4.03          0.001536   \n",
       "1            use          use          21        2.17          0.000942   \n",
       "2           cost         cost           6        2.79          0.000354   \n",
       "3   restrictions  restriction           2        4.18          0.000963   \n",
       "4     whatsoever   whatsoever           3        4.01          0.001467   \n",
       "..           ...          ...         ...         ...               ...   \n",
       "95       worries        worry           6        3.16          0.000828   \n",
       "96        making         make          14        1.95          0.000279   \n",
       "97   connections   connection           2        3.23          0.000108   \n",
       "98           bad          bad           4        2.47          0.000075   \n",
       "99     irregular    irregular           1        4.26          0.000289   \n",
       "\n",
       "    cluster  \n",
       "0         9  \n",
       "1         9  \n",
       "2         7  \n",
       "3         7  \n",
       "4         7  \n",
       "..      ...  \n",
       "95        1  \n",
       "96        1  \n",
       "97        9  \n",
       "98        1  \n",
       "99        6  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for token in doc:\n",
    "    if not token._.is_excluded:\n",
    "        data.append((token, token.lemma_, token._.appearance, token._.difficulty, token._.relativ_freq, token._.cluster))\n",
    "df = pd.DataFrame(data, columns=['token', 'lemma', 'appearance', 'difficulty', 'relativ freqency', 'cluster'])\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>swinging</td>\n",
       "      <td>swinge</td>\n",
       "      <td>1</td>\n",
       "      <td>8.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>saddened</td>\n",
       "      <td>sadden</td>\n",
       "      <td>1</td>\n",
       "      <td>5.97</td>\n",
       "      <td>0.014879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>assailed</td>\n",
       "      <td>assail</td>\n",
       "      <td>1</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>hearer</td>\n",
       "      <td>hearer</td>\n",
       "      <td>1</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>rumination</td>\n",
       "      <td>rumination</td>\n",
       "      <td>1</td>\n",
       "      <td>5.82</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>incarcerated</td>\n",
       "      <td>incarcerate</td>\n",
       "      <td>1</td>\n",
       "      <td>5.81</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>perversity</td>\n",
       "      <td>perversity</td>\n",
       "      <td>1</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>construed</td>\n",
       "      <td>construe</td>\n",
       "      <td>1</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>unthinking</td>\n",
       "      <td>unthinking</td>\n",
       "      <td>1</td>\n",
       "      <td>5.74</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>protrusions</td>\n",
       "      <td>protrusion</td>\n",
       "      <td>1</td>\n",
       "      <td>5.68</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>resounding</td>\n",
       "      <td>resound</td>\n",
       "      <td>1</td>\n",
       "      <td>5.65</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>disclaim</td>\n",
       "      <td>disclaim</td>\n",
       "      <td>1</td>\n",
       "      <td>5.59</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>protruding</td>\n",
       "      <td>protrude</td>\n",
       "      <td>2</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>flecks</td>\n",
       "      <td>fleck</td>\n",
       "      <td>1</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>indemnify</td>\n",
       "      <td>indemnify</td>\n",
       "      <td>1</td>\n",
       "      <td>5.56</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>invalidity</td>\n",
       "      <td>invalidity</td>\n",
       "      <td>1</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>proofread</td>\n",
       "      <td>proofread</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>unpleasantness</td>\n",
       "      <td>unpleasantness</td>\n",
       "      <td>1</td>\n",
       "      <td>5.47</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>captivate</td>\n",
       "      <td>captivate</td>\n",
       "      <td>1</td>\n",
       "      <td>5.41</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>groundless</td>\n",
       "      <td>groundless</td>\n",
       "      <td>1</td>\n",
       "      <td>5.41</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               token           lemma  appearance  difficulty  \\\n",
       "302         swinging          swinge           1        8.00   \n",
       "827         saddened          sadden           1        5.97   \n",
       "858         assailed          assail           1        5.91   \n",
       "203           hearer          hearer           1        5.90   \n",
       "1146      rumination      rumination           1        5.82   \n",
       "735     incarcerated     incarcerate           1        5.81   \n",
       "846       perversity      perversity           1        5.76   \n",
       "711        construed        construe           1        5.76   \n",
       "582       unthinking      unthinking           1        5.74   \n",
       "923      protrusions      protrusion           1        5.68   \n",
       "589       resounding         resound           1        5.65   \n",
       "1331        disclaim        disclaim           1        5.59   \n",
       "554       protruding        protrude           2        5.57   \n",
       "617           flecks           fleck           1        5.57   \n",
       "1361       indemnify       indemnify           1        5.56   \n",
       "1358      invalidity      invalidity           1        5.54   \n",
       "1314       proofread       proofread           1        5.52   \n",
       "666   unpleasantness  unpleasantness           1        5.47   \n",
       "1085       captivate       captivate           1        5.41   \n",
       "545       groundless      groundless           1        5.41   \n",
       "\n",
       "      relativ freqency  cluster  \n",
       "302                NaN        6  \n",
       "827           0.014879        4  \n",
       "858           0.012944        4  \n",
       "203           0.012636        4  \n",
       "1146          0.010544        4  \n",
       "735           0.010272        4  \n",
       "846           0.009150        4  \n",
       "711           0.009150        7  \n",
       "582           0.008748        4  \n",
       "923           0.007618        6  \n",
       "589           0.007108        4  \n",
       "1331          0.006195        7  \n",
       "554           0.023674        6  \n",
       "617           0.005919        6  \n",
       "1361          0.005789        7  \n",
       "1358          0.005528        7  \n",
       "1314          0.005272        9  \n",
       "666           0.004696        4  \n",
       "1085          0.004093        4  \n",
       "545           0.004093        4  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['difficulty'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>distribute</td>\n",
       "      <td>distribute</td>\n",
       "      <td>17</td>\n",
       "      <td>4.21</td>\n",
       "      <td>0.074573</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>locksmith</td>\n",
       "      <td>locksmith</td>\n",
       "      <td>4</td>\n",
       "      <td>5.35</td>\n",
       "      <td>0.056988</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>donations</td>\n",
       "      <td>donation</td>\n",
       "      <td>16</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.043684</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>violin</td>\n",
       "      <td>violin</td>\n",
       "      <td>12</td>\n",
       "      <td>4.28</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>COPYRIGHTED</td>\n",
       "      <td>copyright</td>\n",
       "      <td>21</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>couch</td>\n",
       "      <td>couch</td>\n",
       "      <td>17</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0.035668</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>trademark</td>\n",
       "      <td>trademark</td>\n",
       "      <td>11</td>\n",
       "      <td>4.14</td>\n",
       "      <td>0.026608</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>clothes</td>\n",
       "      <td>clothe</td>\n",
       "      <td>3</td>\n",
       "      <td>5.23</td>\n",
       "      <td>0.024327</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>protruding</td>\n",
       "      <td>protrude</td>\n",
       "      <td>2</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>refund</td>\n",
       "      <td>refund</td>\n",
       "      <td>9</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>painfully</td>\n",
       "      <td>painfully</td>\n",
       "      <td>6</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>parents</td>\n",
       "      <td>parent</td>\n",
       "      <td>26</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.017119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>slowly</td>\n",
       "      <td>slowly</td>\n",
       "      <td>22</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.015272</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>saddened</td>\n",
       "      <td>sadden</td>\n",
       "      <td>1</td>\n",
       "      <td>5.97</td>\n",
       "      <td>0.014879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>complying</td>\n",
       "      <td>comply</td>\n",
       "      <td>9</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.014474</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>broom</td>\n",
       "      <td>broom</td>\n",
       "      <td>5</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.014114</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>disturbed</td>\n",
       "      <td>disturb</td>\n",
       "      <td>6</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.013745</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>paragraph</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>11</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>legs</td>\n",
       "      <td>leg</td>\n",
       "      <td>21</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.013295</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>assailed</td>\n",
       "      <td>assail</td>\n",
       "      <td>1</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>astonished</td>\n",
       "      <td>astonished</td>\n",
       "      <td>4</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0.012737</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>hearer</td>\n",
       "      <td>hearer</td>\n",
       "      <td>1</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>reproach</td>\n",
       "      <td>reproach</td>\n",
       "      <td>3</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>DISCLAIMER</td>\n",
       "      <td>disclaimer</td>\n",
       "      <td>4</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.011904</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>hardly</td>\n",
       "      <td>hardly</td>\n",
       "      <td>16</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.011746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>copy</td>\n",
       "      <td>copy</td>\n",
       "      <td>24</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>redistributing</td>\n",
       "      <td>redistribute</td>\n",
       "      <td>2</td>\n",
       "      <td>5.22</td>\n",
       "      <td>0.010561</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>rumination</td>\n",
       "      <td>rumination</td>\n",
       "      <td>1</td>\n",
       "      <td>5.82</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>incarcerated</td>\n",
       "      <td>incarcerate</td>\n",
       "      <td>1</td>\n",
       "      <td>5.81</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>chest</td>\n",
       "      <td>chest</td>\n",
       "      <td>14</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.009875</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               token         lemma  appearance  difficulty  relativ freqency  \\\n",
       "1208      distribute    distribute          17        4.21          0.074573   \n",
       "461        locksmith     locksmith           4        5.35          0.056988   \n",
       "1297       donations      donation          16        4.03          0.043684   \n",
       "780           violin        violin          12        4.28          0.043669   \n",
       "10       COPYRIGHTED     copyright          21        3.76          0.036600   \n",
       "656            couch         couch          17        3.89          0.035668   \n",
       "1214       trademark     trademark          11        4.14          0.026608   \n",
       "777          clothes        clothe           3        5.23          0.024327   \n",
       "554       protruding      protrude           2        5.57          0.023674   \n",
       "1238          refund        refund           9        4.22          0.021386   \n",
       "260        painfully     painfully           6        4.54          0.019901   \n",
       "122          parents        parent          26        3.43          0.017119   \n",
       "106           slowly        slowly          22        3.38          0.015272   \n",
       "827         saddened        sadden           1        5.97          0.014879   \n",
       "1218       complying        comply           9        4.05          0.014474   \n",
       "701            broom         broom           5        4.55          0.014114   \n",
       "234        disturbed       disturb           6        4.38          0.013745   \n",
       "1240       paragraph     paragraph          11        3.85          0.013663   \n",
       "44              legs           leg          21        3.32          0.013295   \n",
       "858         assailed        assail           1        5.91          0.012944   \n",
       "406       astonished    astonished           4        4.70          0.012737   \n",
       "203           hearer        hearer           1        5.90          0.012636   \n",
       "878         reproach      reproach           3        4.93          0.012247   \n",
       "1329      DISCLAIMER    disclaimer           4        4.67          0.011904   \n",
       "39            hardly        hardly          16        3.46          0.011746   \n",
       "5               copy          copy          24        3.24          0.011075   \n",
       "1262  redistributing  redistribute           2        5.22          0.010561   \n",
       "1146      rumination    rumination           1        5.82          0.010544   \n",
       "735     incarcerated   incarcerate           1        5.81          0.010272   \n",
       "143            chest         chest          14        3.50          0.009875   \n",
       "\n",
       "      cluster  \n",
       "1208        7  \n",
       "461         7  \n",
       "1297        7  \n",
       "780         6  \n",
       "10          9  \n",
       "656         6  \n",
       "1214        7  \n",
       "777         6  \n",
       "554         6  \n",
       "1238        7  \n",
       "260         4  \n",
       "122         1  \n",
       "106         6  \n",
       "827         4  \n",
       "1218        7  \n",
       "701         6  \n",
       "234         4  \n",
       "1240        9  \n",
       "44          6  \n",
       "858         4  \n",
       "406         4  \n",
       "203         4  \n",
       "878         4  \n",
       "1329        7  \n",
       "39          1  \n",
       "5           9  \n",
       "1262        7  \n",
       "1146        4  \n",
       "735         4  \n",
       "143         6  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['relativ freqency'], ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Translated</td>\n",
       "      <td>translate</td>\n",
       "      <td>3</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>events</td>\n",
       "      <td>event</td>\n",
       "      <td>1</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>normally</td>\n",
       "      <td>normally</td>\n",
       "      <td>3</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>write</td>\n",
       "      <td>write</td>\n",
       "      <td>8</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>reading</td>\n",
       "      <td>reading</td>\n",
       "      <td>1</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>recent</td>\n",
       "      <td>recent</td>\n",
       "      <td>1</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>wealth</td>\n",
       "      <td>wealth</td>\n",
       "      <td>1</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>arrange</td>\n",
       "      <td>arrange</td>\n",
       "      <td>3</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>ease</td>\n",
       "      <td>ease</td>\n",
       "      <td>1</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>frequently</td>\n",
       "      <td>frequently</td>\n",
       "      <td>2</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>opportunity</td>\n",
       "      <td>opportunity</td>\n",
       "      <td>4</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>subscribe</td>\n",
       "      <td>subscribe</td>\n",
       "      <td>1</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>possibilities</td>\n",
       "      <td>possibility</td>\n",
       "      <td>2</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>selection</td>\n",
       "      <td>selection</td>\n",
       "      <td>1</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>news</td>\n",
       "      <td>news</td>\n",
       "      <td>3</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>value</td>\n",
       "      <td>value</td>\n",
       "      <td>1</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>palely</td>\n",
       "      <td>palely</td>\n",
       "      <td>1</td>\n",
       "      <td>6.87</td>\n",
       "      <td>0.117933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>leading</td>\n",
       "      <td>lead</td>\n",
       "      <td>5</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>fully</td>\n",
       "      <td>fully</td>\n",
       "      <td>7</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>particular</td>\n",
       "      <td>particular</td>\n",
       "      <td>6</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>overview</td>\n",
       "      <td>overview</td>\n",
       "      <td>2</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>staff</td>\n",
       "      <td>staff</td>\n",
       "      <td>2</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>usually</td>\n",
       "      <td>usually</td>\n",
       "      <td>3</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>effects</td>\n",
       "      <td>effect</td>\n",
       "      <td>2</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>save</td>\n",
       "      <td>save</td>\n",
       "      <td>6</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>provide</td>\n",
       "      <td>provide</td>\n",
       "      <td>18</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>directly</td>\n",
       "      <td>directly</td>\n",
       "      <td>3</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>future</td>\n",
       "      <td>future</td>\n",
       "      <td>7</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>relatively</td>\n",
       "      <td>relatively</td>\n",
       "      <td>3</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>practice</td>\n",
       "      <td>practice</td>\n",
       "      <td>1</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>choice</td>\n",
       "      <td>choice</td>\n",
       "      <td>2</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>frequent</td>\n",
       "      <td>frequent</td>\n",
       "      <td>2</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>preparation</td>\n",
       "      <td>preparation</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>experience</td>\n",
       "      <td>experience</td>\n",
       "      <td>3</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>fast</td>\n",
       "      <td>fast</td>\n",
       "      <td>3</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>numerous</td>\n",
       "      <td>numerous</td>\n",
       "      <td>2</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>appropriate</td>\n",
       "      <td>appropriate</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>similar</td>\n",
       "      <td>similar</td>\n",
       "      <td>1</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>add</td>\n",
       "      <td>add</td>\n",
       "      <td>2</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>freely</td>\n",
       "      <td>freely</td>\n",
       "      <td>5</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>express</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>communication</td>\n",
       "      <td>communication</td>\n",
       "      <td>1</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>influence</td>\n",
       "      <td>influence</td>\n",
       "      <td>1</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>loss</td>\n",
       "      <td>loss</td>\n",
       "      <td>1</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>advantage</td>\n",
       "      <td>advantage</td>\n",
       "      <td>1</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>advice</td>\n",
       "      <td>advice</td>\n",
       "      <td>1</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>1</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>writing</td>\n",
       "      <td>writing</td>\n",
       "      <td>5</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>containing</td>\n",
       "      <td>contain</td>\n",
       "      <td>4</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              token          lemma  appearance  difficulty  relativ freqency  \\\n",
       "0        Translated      translate           3        4.03          0.001536   \n",
       "941          events          event           1        2.85          0.000011   \n",
       "959        normally       normally           3        3.40          0.000360   \n",
       "966           write          write           8        2.99          0.000999   \n",
       "967         reading        reading           1        2.92          0.000013   \n",
       "968          recent         recent           1        2.97          0.000015   \n",
       "972          wealth         wealth           1        3.48          0.000048   \n",
       "983         arrange        arrange           3        3.99          0.001405   \n",
       "990            ease           ease           1        3.66          0.000073   \n",
       "994      frequently     frequently           2        3.43          0.000171   \n",
       "1001    opportunity    opportunity           4        3.08          0.000306   \n",
       "1002           test           test           3        2.80          0.000091   \n",
       "2020      subscribe      subscribe           1        4.11          0.000205   \n",
       "1011  possibilities    possibility           2        3.34          0.000139   \n",
       "1014      selection      selection           1        3.37          0.000037   \n",
       "1067           news           news           3        2.59          0.000056   \n",
       "936           value          value           1        2.81          0.000010   \n",
       "931          palely         palely           1        6.87          0.117933   \n",
       "927         leading           lead           5        2.80          0.000252   \n",
       "924           fully          fully           7        3.14          0.001078   \n",
       "787      particular     particular           6        2.92          0.000478   \n",
       "788        overview       overview           2        3.87          0.000472   \n",
       "789           staff          staff           2        2.94          0.000055   \n",
       "800         usually        usually           3        2.84          0.000099   \n",
       "805         effects         effect           2        2.90          0.000051   \n",
       "822            save           save           6        2.91          0.000466   \n",
       "826         provide        provide          18        2.88          0.003908   \n",
       "1068       directly       directly           3        3.08          0.000172   \n",
       "827          future         future           7        2.67          0.000365   \n",
       "867      relatively     relatively           3        3.31          0.000292   \n",
       "885        practice       practice           1        2.93          0.000014   \n",
       "889          choice         choice           2        2.92          0.000053   \n",
       "892        frequent       frequent           2        3.70          0.000318   \n",
       "905     preparation    preparation           1        3.62          0.000066   \n",
       "907      experience     experience           3        2.71          0.000073   \n",
       "914            fast           fast           3        2.91          0.000116   \n",
       "840        numerous       numerous           2        3.30          0.000127   \n",
       "1070    appropriate    appropriate           1        3.29          0.000031   \n",
       "1083        similar        similar           1        2.77          0.000009   \n",
       "1086            add            add           2        2.93          0.000054   \n",
       "1219         freely         freely           5        3.89          0.003085   \n",
       "1226        express        express           1        3.32          0.000033   \n",
       "1246  communication  communication           1        3.31          0.000032   \n",
       "1253      influence      influence           1        3.18          0.000024   \n",
       "1255           loss           loss           1        2.95          0.000014   \n",
       "1256      advantage      advantage           1        3.21          0.000026   \n",
       "1260         advice         advice           1        3.12          0.000021   \n",
       "1216          adult          adult           1        3.24          0.000028   \n",
       "1271        writing        writing           5        2.94          0.000346   \n",
       "1285     containing        contain           4        3.43          0.000685   \n",
       "\n",
       "      cluster  \n",
       "0           0  \n",
       "941         0  \n",
       "959         0  \n",
       "966         0  \n",
       "967         0  \n",
       "968         0  \n",
       "972         0  \n",
       "983         0  \n",
       "990         0  \n",
       "994         0  \n",
       "1001        0  \n",
       "1002        0  \n",
       "2020        0  \n",
       "1011        0  \n",
       "1014        0  \n",
       "1067        0  \n",
       "936         0  \n",
       "931         0  \n",
       "927         0  \n",
       "924         0  \n",
       "787         0  \n",
       "788         0  \n",
       "789         0  \n",
       "800         0  \n",
       "805         0  \n",
       "822         0  \n",
       "826         0  \n",
       "1068        0  \n",
       "827         0  \n",
       "867         0  \n",
       "885         0  \n",
       "889         0  \n",
       "892         0  \n",
       "905         0  \n",
       "907         0  \n",
       "914         0  \n",
       "840         0  \n",
       "1070        0  \n",
       "1083        0  \n",
       "1086        0  \n",
       "1219        0  \n",
       "1226        0  \n",
       "1246        0  \n",
       "1253        0  \n",
       "1255        0  \n",
       "1256        0  \n",
       "1260        0  \n",
       "1216        0  \n",
       "1271        0  \n",
       "1285        0  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['cluster'], ascending=True).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 overall words\n",
      "21 words included\n",
      "18 words without duplicate included\n",
      "4\n",
      "[0, 2]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I love cars, which drive very fast and loud. Trucks and vans are the best. My mother is all in to cooking good meals, foods and healthy dishes. This keeps me healthy while. I love the pasta and pies she bakes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['car', 'drive', 'fast', 'truck', 'van', 'good', 'cook', 'meal', 'food', 'healthy', 'dish', 'pasta', 'pie', 'bake']]\n"
     ]
    }
   ],
   "source": [
    "words = [[token.lemma_ for token in doc if not token._.is_excluded]]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cars</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.261916</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drive</td>\n",
       "      <td>drive</td>\n",
       "      <td>1</td>\n",
       "      <td>2.91</td>\n",
       "      <td>4.836455</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fast</td>\n",
       "      <td>fast</td>\n",
       "      <td>1</td>\n",
       "      <td>2.91</td>\n",
       "      <td>4.836455</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trucks</td>\n",
       "      <td>truck</td>\n",
       "      <td>1</td>\n",
       "      <td>3.45</td>\n",
       "      <td>16.757296</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vans</td>\n",
       "      <td>van</td>\n",
       "      <td>1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>9.427639</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>best</td>\n",
       "      <td>good</td>\n",
       "      <td>2</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.802679</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cooking</td>\n",
       "      <td>cook</td>\n",
       "      <td>1</td>\n",
       "      <td>3.37</td>\n",
       "      <td>13.931710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meals</td>\n",
       "      <td>meal</td>\n",
       "      <td>1</td>\n",
       "      <td>3.53</td>\n",
       "      <td>20.165559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>foods</td>\n",
       "      <td>food</td>\n",
       "      <td>1</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.261916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>2</td>\n",
       "      <td>3.22</td>\n",
       "      <td>39.461625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dishes</td>\n",
       "      <td>dish</td>\n",
       "      <td>1</td>\n",
       "      <td>3.84</td>\n",
       "      <td>41.026483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pasta</td>\n",
       "      <td>pasta</td>\n",
       "      <td>1</td>\n",
       "      <td>4.14</td>\n",
       "      <td>82.166298</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pies</td>\n",
       "      <td>pie</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>39.396291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bakes</td>\n",
       "      <td>bake</td>\n",
       "      <td>1</td>\n",
       "      <td>4.17</td>\n",
       "      <td>88.000591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token    lemma  appearance  difficulty  relativ freqency  cluster\n",
       "0      cars      car           1        2.58          2.261916        3\n",
       "1     drive    drive           1        2.91          4.836455        3\n",
       "2      fast     fast           1        2.91          4.836455        3\n",
       "3    Trucks    truck           1        3.45         16.757296        3\n",
       "4      vans      van           1        3.20          9.427639        3\n",
       "5      best     good           2        1.88          1.802679        3\n",
       "6   cooking     cook           1        3.37         13.931710        1\n",
       "7     meals     meal           1        3.53         20.165559        1\n",
       "8     foods     food           1        2.58          2.261916        1\n",
       "9   healthy  healthy           2        3.22         39.461625        1\n",
       "10   dishes     dish           1        3.84         41.026483        1\n",
       "11    pasta    pasta           1        4.14         82.166298        1\n",
       "12     pies      pie           1        3.82         39.396291        1\n",
       "13    bakes     bake           1        4.17         88.000591        1"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for token in doc:\n",
    "    if not token._.is_excluded:\n",
    "        data.append((token, token.lemma_, token._.appearance, token._.difficulty, token._.relativ_freq, token._.cluster))\n",
    "df = pd.DataFrame(data, columns=['token', 'lemma', 'appearance', 'difficulty', 'relativ freqency', 'cluster'])\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3, 3: 6, 1: 8, 2: 1})"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.cluster_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TextAnalytics] *",
   "language": "python",
   "name": "conda-env-TextAnalytics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

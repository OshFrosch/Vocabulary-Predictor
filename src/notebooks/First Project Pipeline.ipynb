{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Project Pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Token\n",
    "from spacy.tokens import Doc\n",
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordfreq import zipf_frequency\n",
    "from wordfreq import word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "\n",
    "phoneme_dict = dict(cmudict.entries())\n",
    "\n",
    "def syllable_counter(word):\n",
    "    '''function that counts a syllable in a word'''\n",
    "    if word not in phoneme_dict:\n",
    "        return 0\n",
    "    syllables = phoneme_dict[word]\n",
    "    count = len([syllable for syllable in syllables if syllable[-1].isdigit()])\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.0\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = '../data/kafka.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(open(text_file, \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg', disable = ['parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'ner']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc.set_extension('wordcount', default=0, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcount(doc):\n",
    "    '''gives an overall word count'''\n",
    "    wordcount = 0\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            wordcount += 1\n",
    "            \n",
    "    doc._.wordcount = wordcount\n",
    "    \n",
    "    print(f'{wordcount} overall words')\n",
    "         \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'ner', 'wordcount']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(wordcount)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension('is_excluded', default=False, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tokens(doc):\n",
    "    '''filters all tokens'''           \n",
    "    \n",
    "    for token in doc:\n",
    "        # filter stopwords\n",
    "        if not token.is_alpha or token.is_stop:\n",
    "            token._.is_excluded = True\n",
    "        # filter part-of-speech\n",
    "        elif token.pos_ not in ['NOUN', 'VERB', 'ADJ', 'ADV']: # ADV?\n",
    "            token._.is_excluded = True\n",
    "        # filter entities\n",
    "        elif token.ent_type != 0:\n",
    "                token._.is_excluded = True\n",
    "         \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(doc):\n",
    "    c = 0\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            c += 1\n",
    "    print(f'{c} words included')\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'ner', 'wordcount', 'filter_tokens', 'count_words']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(filter_tokens)\n",
    "nlp.add_pipe(count_words)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension('appearance', default=np.nan, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elim_dup(doc):\n",
    "    '''eliminates all duplicates and counts the appearance of the included words'''\n",
    "    already_appeared = {}\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            if token.lemma_ in already_appeared.keys():\n",
    "                already_appeared[token.lemma_] += 1\n",
    "                token._.is_excluded = True\n",
    "            else: \n",
    "                already_appeared[token.lemma_] = 1\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            token._.appearance = already_appeared[token.lemma_]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_voc(doc):\n",
    "    c = 0\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            c += 1\n",
    "    print(f'{c} words without duplicate included')\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger',\n",
       " 'ner',\n",
       " 'wordcount',\n",
       " 'filter_tokens',\n",
       " 'count_words',\n",
       " 'elim_dup',\n",
       " 'count_voc']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(elim_dup)\n",
    "nlp.add_pipe(count_voc)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Freqency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension('relativ_freq', default=np.nan, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relativ_freq(doc):\n",
    "    '''calculating the relativ frequency of a included word'''\n",
    "    \n",
    "    maw = 20 # maximal appearance weight\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            text_freq = min(maw, token._.appearance) / doc._.wordcount\n",
    "            overall_freq = word_frequency(token.lemma_, 'en')\n",
    "            if overall_freq != 0:\n",
    "                token._.relativ_freq = text_freq**2 / overall_freq\n",
    "        \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger',\n",
       " 'ner',\n",
       " 'wordcount',\n",
       " 'filter_tokens',\n",
       " 'count_words',\n",
       " 'elim_dup',\n",
       " 'count_voc',\n",
       " 'calculate_relativ_freq']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(calculate_relativ_freq)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension('difficulty', default=0, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difficulty(doc):\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            lemma = token.lemma_\n",
    "            readability = zipf_frequency(lemma, 'en') # score of 1-8\n",
    "            syl = syllable_counter(lemma)\n",
    "            if syl > 1 and readability != 0 :\n",
    "                readability -= 0 #(syl - 2)/2\n",
    "            token._.difficulty = round(8 - readability, 2)\n",
    "            \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger',\n",
       " 'ner',\n",
       " 'wordcount',\n",
       " 'filter_tokens',\n",
       " 'count_words',\n",
       " 'elim_dup',\n",
       " 'count_voc',\n",
       " 'calculate_relativ_freq',\n",
       " 'get_difficulty']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(get_difficulty)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Token.set_extension('cluster', default=np.nan, force=True)\\nDoc.set_extension('cluster_sizes', default=0, force=True)\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Token.set_extension('cluster', default=np.nan, force=True)\n",
    "Doc.set_extension('cluster_sizes', default=0, force=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_words(doc):\n",
    "    \n",
    "    X = [tok.vector for tok in doc if not tok._.is_excluded]\n",
    "    dist = nltk.cluster.util.cosine_distance\n",
    "    k = int(round(np.log(doc._.wordcount), 0 )) #prototype\n",
    "    print(k)\n",
    "    \n",
    "    kclusterer = nltk.cluster.KMeansClusterer(k, distance=dist)\n",
    "    assigned_clusters = kclusterer.cluster(X, assign_clusters=True)\n",
    "    clusters = iter(assigned_clusters)\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            token._.cluster = next(clusters)\n",
    "    \n",
    "    doc._.cluster_sizes = collections.Counter(assigned_clusters)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_smallest_clusters(doc):\n",
    "    \n",
    "    cluster_count = len(doc._.cluster_sizes)\n",
    "    smallest_clusters = []\n",
    "    for i in range(int(cluster_count * 2/3), cluster_count):\n",
    "        c = doc._.cluster_sizes.most_common()[i][0]\n",
    "        smallest_clusters.append(c)\n",
    "        \n",
    "    print(smallest_clusters)\n",
    "        \n",
    "    for token in doc:\n",
    "        if not token._.is_excluded:\n",
    "            if token._.cluster in smallest_clusters:\n",
    "                token._.is_excluded = True\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nlp.add_pipe(cluster_words)\\nnlp.add_pipe(exclude_smallest_clusters)\\nnlp.pipe_names'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''nlp.add_pipe(cluster_words)\n",
    "nlp.add_pipe(exclude_smallest_clusters)\n",
    "nlp.pipe_names'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc.set_extension('keywords', default=[], force=True)\n",
    "Token.set_extension('is_keyword', default=False, force=True)\n",
    "Token.set_extension('keyword_score', default=-20, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_keyphrases(doc):\n",
    "    \n",
    "    kw = keywords(doc.text, split=True)\n",
    "    \n",
    "    keywords_token = []\n",
    "    already_in_list = []\n",
    "    for token in doc:\n",
    "        if token.text in kw:\n",
    "            token._.is_keyword = True\n",
    "            if token.text not in already_in_list:\n",
    "                keywords_token.append(token)\n",
    "                already_in_list.append(token.text)\n",
    "    doc._.keywords = keywords_token\n",
    "    \n",
    "    print(f'{len(keywords_token)} keywords found')\n",
    "    \n",
    "    for token in doc:\n",
    "        for kw in keywords_token:\n",
    "            kw_score = token.similarity(kw)\n",
    "            if kw_score > token._.keyword_score:\n",
    "                token._.keyword_score =  kw_score\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger',\n",
       " 'ner',\n",
       " 'wordcount',\n",
       " 'filter_tokens',\n",
       " 'count_words',\n",
       " 'elim_dup',\n",
       " 'count_voc',\n",
       " 'calculate_relativ_freq',\n",
       " 'get_difficulty',\n",
       " 'check_keyphrases']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(check_keyphrases)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test scentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 overall words\n",
      "9 words included\n",
      "6 words without duplicate included\n",
      "Keywords: 0\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Hi I'm a little little boy. Get me a piece of cake or I'll killed your mother. I am the mother of your mother\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc._.cluster_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "[E046] Can't retrieve unregistered extension attribute 'cluster'. Did you forget to call the `set_extension` method?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-8bff1623ae1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_excluded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappearance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifficulty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelativ_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lemma'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'appearance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'difficulty'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'relativ freqency'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/TextAnalytics2.2/lib/python3.8/site-packages/spacy/tokens/underscore.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE046\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extensions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: [E046] Can't retrieve unregistered extension attribute 'cluster'. Did you forget to call the `set_extension` method?"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for token in doc:\n",
    "    if not token._.is_excluded:\n",
    "        data.append((token, token.lemma_, token._.appearance, token._.difficulty, token._.relativ_freq, token._.cluster))\n",
    "df = pd.DataFrame(data, columns=['token', 'lemma', 'appearance', 'difficulty', 'relativ freqency', 'cluster'])\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cake</td>\n",
       "      <td>cake</td>\n",
       "      <td>1</td>\n",
       "      <td>3.57</td>\n",
       "      <td>64.539447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>piece</td>\n",
       "      <td>piece</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>18.607836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy</td>\n",
       "      <td>boy</td>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>10.988045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mother</td>\n",
       "      <td>mother</td>\n",
       "      <td>3</td>\n",
       "      <td>2.72</td>\n",
       "      <td>81.806283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>2</td>\n",
       "      <td>2.25</td>\n",
       "      <td>12.356663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token   lemma  appearance  difficulty  relativ freqency  cluster\n",
       "3    cake    cake           1        3.57         64.539447        0\n",
       "2   piece   piece           1        3.03         18.607836        0\n",
       "1     boy     boy           1        2.80         10.988045        1\n",
       "4  mother  mother           3        2.72         81.806283        1\n",
       "0  little  little           2        2.25         12.356663        1"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['difficulty'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mother</td>\n",
       "      <td>mother</td>\n",
       "      <td>3</td>\n",
       "      <td>2.72</td>\n",
       "      <td>81.806283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cake</td>\n",
       "      <td>cake</td>\n",
       "      <td>1</td>\n",
       "      <td>3.57</td>\n",
       "      <td>64.539447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>piece</td>\n",
       "      <td>piece</td>\n",
       "      <td>1</td>\n",
       "      <td>3.03</td>\n",
       "      <td>18.607836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>2</td>\n",
       "      <td>2.25</td>\n",
       "      <td>12.356663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy</td>\n",
       "      <td>boy</td>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>10.988045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token   lemma  appearance  difficulty  relativ freqency  cluster\n",
       "4  mother  mother           3        2.72         81.806283        1\n",
       "3    cake    cake           1        3.57         64.539447        0\n",
       "2   piece   piece           1        3.03         18.607836        0\n",
       "0  little  little           2        2.25         12.356663        1\n",
       "1     boy     boy           1        2.80         10.988045        1"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['relativ freqency'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25062 overall words\n",
      "8460 words included\n",
      "2047 words without duplicate included\n",
      "Keywords: 440\n"
     ]
    }
   ],
   "source": [
    "with open(text_file, \"r\") as f:\n",
    "    doc = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc._.keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 255,\n",
       "         0: 225,\n",
       "         7: 340,\n",
       "         4: 245,\n",
       "         8: 162,\n",
       "         1: 268,\n",
       "         2: 158,\n",
       "         5: 120,\n",
       "         3: 176,\n",
       "         9: 73})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.cluster_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Translated</td>\n",
       "      <td>translate</td>\n",
       "      <td>3</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>21</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cost</td>\n",
       "      <td>cost</td>\n",
       "      <td>6</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>restrictions</td>\n",
       "      <td>restriction</td>\n",
       "      <td>2</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whatsoever</td>\n",
       "      <td>whatsoever</td>\n",
       "      <td>3</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>worries</td>\n",
       "      <td>worry</td>\n",
       "      <td>6</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>making</td>\n",
       "      <td>make</td>\n",
       "      <td>14</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>connections</td>\n",
       "      <td>connection</td>\n",
       "      <td>2</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>4</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>irregular</td>\n",
       "      <td>irregular</td>\n",
       "      <td>1</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           token        lemma  appearance  difficulty  relativ freqency  \\\n",
       "0     Translated    translate           3        4.03          0.001536   \n",
       "1            use          use          21        2.17          0.000942   \n",
       "2           cost         cost           6        2.79          0.000354   \n",
       "3   restrictions  restriction           2        4.18          0.000963   \n",
       "4     whatsoever   whatsoever           3        4.01          0.001467   \n",
       "..           ...          ...         ...         ...               ...   \n",
       "95       worries        worry           6        3.16          0.000828   \n",
       "96        making         make          14        1.95          0.000279   \n",
       "97   connections   connection           2        3.23          0.000108   \n",
       "98           bad          bad           4        2.47          0.000075   \n",
       "99     irregular    irregular           1        4.26          0.000289   \n",
       "\n",
       "    cluster  \n",
       "0         9  \n",
       "1         9  \n",
       "2         7  \n",
       "3         7  \n",
       "4         7  \n",
       "..      ...  \n",
       "95        1  \n",
       "96        1  \n",
       "97        9  \n",
       "98        1  \n",
       "99        6  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for token in doc:\n",
    "    if not token._.is_excluded:\n",
    "        data.append((token, token.lemma_, token._.appearance, token._.difficulty, token._.relativ_freq, token._.cluster))\n",
    "df = pd.DataFrame(data, columns=['token', 'lemma', 'appearance', 'difficulty', 'relativ freqency', 'cluster'])\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>swinging</td>\n",
       "      <td>swinge</td>\n",
       "      <td>1</td>\n",
       "      <td>8.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>saddened</td>\n",
       "      <td>sadden</td>\n",
       "      <td>1</td>\n",
       "      <td>5.97</td>\n",
       "      <td>0.014879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>assailed</td>\n",
       "      <td>assail</td>\n",
       "      <td>1</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>hearer</td>\n",
       "      <td>hearer</td>\n",
       "      <td>1</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>rumination</td>\n",
       "      <td>rumination</td>\n",
       "      <td>1</td>\n",
       "      <td>5.82</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>incarcerated</td>\n",
       "      <td>incarcerate</td>\n",
       "      <td>1</td>\n",
       "      <td>5.81</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>perversity</td>\n",
       "      <td>perversity</td>\n",
       "      <td>1</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>construed</td>\n",
       "      <td>construe</td>\n",
       "      <td>1</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>unthinking</td>\n",
       "      <td>unthinking</td>\n",
       "      <td>1</td>\n",
       "      <td>5.74</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>protrusions</td>\n",
       "      <td>protrusion</td>\n",
       "      <td>1</td>\n",
       "      <td>5.68</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>resounding</td>\n",
       "      <td>resound</td>\n",
       "      <td>1</td>\n",
       "      <td>5.65</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>disclaim</td>\n",
       "      <td>disclaim</td>\n",
       "      <td>1</td>\n",
       "      <td>5.59</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>protruding</td>\n",
       "      <td>protrude</td>\n",
       "      <td>2</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>flecks</td>\n",
       "      <td>fleck</td>\n",
       "      <td>1</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>indemnify</td>\n",
       "      <td>indemnify</td>\n",
       "      <td>1</td>\n",
       "      <td>5.56</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>invalidity</td>\n",
       "      <td>invalidity</td>\n",
       "      <td>1</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>proofread</td>\n",
       "      <td>proofread</td>\n",
       "      <td>1</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>unpleasantness</td>\n",
       "      <td>unpleasantness</td>\n",
       "      <td>1</td>\n",
       "      <td>5.47</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>captivate</td>\n",
       "      <td>captivate</td>\n",
       "      <td>1</td>\n",
       "      <td>5.41</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>groundless</td>\n",
       "      <td>groundless</td>\n",
       "      <td>1</td>\n",
       "      <td>5.41</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               token           lemma  appearance  difficulty  \\\n",
       "302         swinging          swinge           1        8.00   \n",
       "827         saddened          sadden           1        5.97   \n",
       "858         assailed          assail           1        5.91   \n",
       "203           hearer          hearer           1        5.90   \n",
       "1146      rumination      rumination           1        5.82   \n",
       "735     incarcerated     incarcerate           1        5.81   \n",
       "846       perversity      perversity           1        5.76   \n",
       "711        construed        construe           1        5.76   \n",
       "582       unthinking      unthinking           1        5.74   \n",
       "923      protrusions      protrusion           1        5.68   \n",
       "589       resounding         resound           1        5.65   \n",
       "1331        disclaim        disclaim           1        5.59   \n",
       "554       protruding        protrude           2        5.57   \n",
       "617           flecks           fleck           1        5.57   \n",
       "1361       indemnify       indemnify           1        5.56   \n",
       "1358      invalidity      invalidity           1        5.54   \n",
       "1314       proofread       proofread           1        5.52   \n",
       "666   unpleasantness  unpleasantness           1        5.47   \n",
       "1085       captivate       captivate           1        5.41   \n",
       "545       groundless      groundless           1        5.41   \n",
       "\n",
       "      relativ freqency  cluster  \n",
       "302                NaN        6  \n",
       "827           0.014879        4  \n",
       "858           0.012944        4  \n",
       "203           0.012636        4  \n",
       "1146          0.010544        4  \n",
       "735           0.010272        4  \n",
       "846           0.009150        4  \n",
       "711           0.009150        7  \n",
       "582           0.008748        4  \n",
       "923           0.007618        6  \n",
       "589           0.007108        4  \n",
       "1331          0.006195        7  \n",
       "554           0.023674        6  \n",
       "617           0.005919        6  \n",
       "1361          0.005789        7  \n",
       "1358          0.005528        7  \n",
       "1314          0.005272        9  \n",
       "666           0.004696        4  \n",
       "1085          0.004093        4  \n",
       "545           0.004093        4  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['difficulty'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>distribute</td>\n",
       "      <td>distribute</td>\n",
       "      <td>17</td>\n",
       "      <td>4.21</td>\n",
       "      <td>0.074573</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>locksmith</td>\n",
       "      <td>locksmith</td>\n",
       "      <td>4</td>\n",
       "      <td>5.35</td>\n",
       "      <td>0.056988</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>donations</td>\n",
       "      <td>donation</td>\n",
       "      <td>16</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.043684</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>violin</td>\n",
       "      <td>violin</td>\n",
       "      <td>12</td>\n",
       "      <td>4.28</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>COPYRIGHTED</td>\n",
       "      <td>copyright</td>\n",
       "      <td>21</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>couch</td>\n",
       "      <td>couch</td>\n",
       "      <td>17</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0.035668</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>trademark</td>\n",
       "      <td>trademark</td>\n",
       "      <td>11</td>\n",
       "      <td>4.14</td>\n",
       "      <td>0.026608</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>clothes</td>\n",
       "      <td>clothe</td>\n",
       "      <td>3</td>\n",
       "      <td>5.23</td>\n",
       "      <td>0.024327</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>protruding</td>\n",
       "      <td>protrude</td>\n",
       "      <td>2</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>refund</td>\n",
       "      <td>refund</td>\n",
       "      <td>9</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>painfully</td>\n",
       "      <td>painfully</td>\n",
       "      <td>6</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>parents</td>\n",
       "      <td>parent</td>\n",
       "      <td>26</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.017119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>slowly</td>\n",
       "      <td>slowly</td>\n",
       "      <td>22</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.015272</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>saddened</td>\n",
       "      <td>sadden</td>\n",
       "      <td>1</td>\n",
       "      <td>5.97</td>\n",
       "      <td>0.014879</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>complying</td>\n",
       "      <td>comply</td>\n",
       "      <td>9</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.014474</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>broom</td>\n",
       "      <td>broom</td>\n",
       "      <td>5</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.014114</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>disturbed</td>\n",
       "      <td>disturb</td>\n",
       "      <td>6</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.013745</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>paragraph</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>11</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>legs</td>\n",
       "      <td>leg</td>\n",
       "      <td>21</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.013295</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>assailed</td>\n",
       "      <td>assail</td>\n",
       "      <td>1</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>astonished</td>\n",
       "      <td>astonished</td>\n",
       "      <td>4</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0.012737</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>hearer</td>\n",
       "      <td>hearer</td>\n",
       "      <td>1</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>reproach</td>\n",
       "      <td>reproach</td>\n",
       "      <td>3</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>DISCLAIMER</td>\n",
       "      <td>disclaimer</td>\n",
       "      <td>4</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.011904</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>hardly</td>\n",
       "      <td>hardly</td>\n",
       "      <td>16</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.011746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>copy</td>\n",
       "      <td>copy</td>\n",
       "      <td>24</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>redistributing</td>\n",
       "      <td>redistribute</td>\n",
       "      <td>2</td>\n",
       "      <td>5.22</td>\n",
       "      <td>0.010561</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>rumination</td>\n",
       "      <td>rumination</td>\n",
       "      <td>1</td>\n",
       "      <td>5.82</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>incarcerated</td>\n",
       "      <td>incarcerate</td>\n",
       "      <td>1</td>\n",
       "      <td>5.81</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>chest</td>\n",
       "      <td>chest</td>\n",
       "      <td>14</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.009875</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               token         lemma  appearance  difficulty  relativ freqency  \\\n",
       "1208      distribute    distribute          17        4.21          0.074573   \n",
       "461        locksmith     locksmith           4        5.35          0.056988   \n",
       "1297       donations      donation          16        4.03          0.043684   \n",
       "780           violin        violin          12        4.28          0.043669   \n",
       "10       COPYRIGHTED     copyright          21        3.76          0.036600   \n",
       "656            couch         couch          17        3.89          0.035668   \n",
       "1214       trademark     trademark          11        4.14          0.026608   \n",
       "777          clothes        clothe           3        5.23          0.024327   \n",
       "554       protruding      protrude           2        5.57          0.023674   \n",
       "1238          refund        refund           9        4.22          0.021386   \n",
       "260        painfully     painfully           6        4.54          0.019901   \n",
       "122          parents        parent          26        3.43          0.017119   \n",
       "106           slowly        slowly          22        3.38          0.015272   \n",
       "827         saddened        sadden           1        5.97          0.014879   \n",
       "1218       complying        comply           9        4.05          0.014474   \n",
       "701            broom         broom           5        4.55          0.014114   \n",
       "234        disturbed       disturb           6        4.38          0.013745   \n",
       "1240       paragraph     paragraph          11        3.85          0.013663   \n",
       "44              legs           leg          21        3.32          0.013295   \n",
       "858         assailed        assail           1        5.91          0.012944   \n",
       "406       astonished    astonished           4        4.70          0.012737   \n",
       "203           hearer        hearer           1        5.90          0.012636   \n",
       "878         reproach      reproach           3        4.93          0.012247   \n",
       "1329      DISCLAIMER    disclaimer           4        4.67          0.011904   \n",
       "39            hardly        hardly          16        3.46          0.011746   \n",
       "5               copy          copy          24        3.24          0.011075   \n",
       "1262  redistributing  redistribute           2        5.22          0.010561   \n",
       "1146      rumination    rumination           1        5.82          0.010544   \n",
       "735     incarcerated   incarcerate           1        5.81          0.010272   \n",
       "143            chest         chest          14        3.50          0.009875   \n",
       "\n",
       "      cluster  \n",
       "1208        7  \n",
       "461         7  \n",
       "1297        7  \n",
       "780         6  \n",
       "10          9  \n",
       "656         6  \n",
       "1214        7  \n",
       "777         6  \n",
       "554         6  \n",
       "1238        7  \n",
       "260         4  \n",
       "122         1  \n",
       "106         6  \n",
       "827         4  \n",
       "1218        7  \n",
       "701         6  \n",
       "234         4  \n",
       "1240        9  \n",
       "44          6  \n",
       "858         4  \n",
       "406         4  \n",
       "203         4  \n",
       "878         4  \n",
       "1329        7  \n",
       "39          1  \n",
       "5           9  \n",
       "1262        7  \n",
       "1146        4  \n",
       "735         4  \n",
       "143         6  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['relativ freqency'], ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Translated</td>\n",
       "      <td>translate</td>\n",
       "      <td>3</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>events</td>\n",
       "      <td>event</td>\n",
       "      <td>1</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>normally</td>\n",
       "      <td>normally</td>\n",
       "      <td>3</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>write</td>\n",
       "      <td>write</td>\n",
       "      <td>8</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>reading</td>\n",
       "      <td>reading</td>\n",
       "      <td>1</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>recent</td>\n",
       "      <td>recent</td>\n",
       "      <td>1</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>wealth</td>\n",
       "      <td>wealth</td>\n",
       "      <td>1</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>arrange</td>\n",
       "      <td>arrange</td>\n",
       "      <td>3</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>ease</td>\n",
       "      <td>ease</td>\n",
       "      <td>1</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>frequently</td>\n",
       "      <td>frequently</td>\n",
       "      <td>2</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>opportunity</td>\n",
       "      <td>opportunity</td>\n",
       "      <td>4</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>subscribe</td>\n",
       "      <td>subscribe</td>\n",
       "      <td>1</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>possibilities</td>\n",
       "      <td>possibility</td>\n",
       "      <td>2</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>selection</td>\n",
       "      <td>selection</td>\n",
       "      <td>1</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>news</td>\n",
       "      <td>news</td>\n",
       "      <td>3</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>value</td>\n",
       "      <td>value</td>\n",
       "      <td>1</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>palely</td>\n",
       "      <td>palely</td>\n",
       "      <td>1</td>\n",
       "      <td>6.87</td>\n",
       "      <td>0.117933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>leading</td>\n",
       "      <td>lead</td>\n",
       "      <td>5</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>fully</td>\n",
       "      <td>fully</td>\n",
       "      <td>7</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>particular</td>\n",
       "      <td>particular</td>\n",
       "      <td>6</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>overview</td>\n",
       "      <td>overview</td>\n",
       "      <td>2</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>staff</td>\n",
       "      <td>staff</td>\n",
       "      <td>2</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>usually</td>\n",
       "      <td>usually</td>\n",
       "      <td>3</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>effects</td>\n",
       "      <td>effect</td>\n",
       "      <td>2</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>save</td>\n",
       "      <td>save</td>\n",
       "      <td>6</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>provide</td>\n",
       "      <td>provide</td>\n",
       "      <td>18</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>directly</td>\n",
       "      <td>directly</td>\n",
       "      <td>3</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>future</td>\n",
       "      <td>future</td>\n",
       "      <td>7</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>relatively</td>\n",
       "      <td>relatively</td>\n",
       "      <td>3</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>practice</td>\n",
       "      <td>practice</td>\n",
       "      <td>1</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>choice</td>\n",
       "      <td>choice</td>\n",
       "      <td>2</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>frequent</td>\n",
       "      <td>frequent</td>\n",
       "      <td>2</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>preparation</td>\n",
       "      <td>preparation</td>\n",
       "      <td>1</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>experience</td>\n",
       "      <td>experience</td>\n",
       "      <td>3</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>fast</td>\n",
       "      <td>fast</td>\n",
       "      <td>3</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>numerous</td>\n",
       "      <td>numerous</td>\n",
       "      <td>2</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>appropriate</td>\n",
       "      <td>appropriate</td>\n",
       "      <td>1</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>similar</td>\n",
       "      <td>similar</td>\n",
       "      <td>1</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>add</td>\n",
       "      <td>add</td>\n",
       "      <td>2</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>freely</td>\n",
       "      <td>freely</td>\n",
       "      <td>5</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>express</td>\n",
       "      <td>express</td>\n",
       "      <td>1</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>communication</td>\n",
       "      <td>communication</td>\n",
       "      <td>1</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>influence</td>\n",
       "      <td>influence</td>\n",
       "      <td>1</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>loss</td>\n",
       "      <td>loss</td>\n",
       "      <td>1</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>advantage</td>\n",
       "      <td>advantage</td>\n",
       "      <td>1</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>advice</td>\n",
       "      <td>advice</td>\n",
       "      <td>1</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>adult</td>\n",
       "      <td>adult</td>\n",
       "      <td>1</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>writing</td>\n",
       "      <td>writing</td>\n",
       "      <td>5</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>containing</td>\n",
       "      <td>contain</td>\n",
       "      <td>4</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              token          lemma  appearance  difficulty  relativ freqency  \\\n",
       "0        Translated      translate           3        4.03          0.001536   \n",
       "941          events          event           1        2.85          0.000011   \n",
       "959        normally       normally           3        3.40          0.000360   \n",
       "966           write          write           8        2.99          0.000999   \n",
       "967         reading        reading           1        2.92          0.000013   \n",
       "968          recent         recent           1        2.97          0.000015   \n",
       "972          wealth         wealth           1        3.48          0.000048   \n",
       "983         arrange        arrange           3        3.99          0.001405   \n",
       "990            ease           ease           1        3.66          0.000073   \n",
       "994      frequently     frequently           2        3.43          0.000171   \n",
       "1001    opportunity    opportunity           4        3.08          0.000306   \n",
       "1002           test           test           3        2.80          0.000091   \n",
       "2020      subscribe      subscribe           1        4.11          0.000205   \n",
       "1011  possibilities    possibility           2        3.34          0.000139   \n",
       "1014      selection      selection           1        3.37          0.000037   \n",
       "1067           news           news           3        2.59          0.000056   \n",
       "936           value          value           1        2.81          0.000010   \n",
       "931          palely         palely           1        6.87          0.117933   \n",
       "927         leading           lead           5        2.80          0.000252   \n",
       "924           fully          fully           7        3.14          0.001078   \n",
       "787      particular     particular           6        2.92          0.000478   \n",
       "788        overview       overview           2        3.87          0.000472   \n",
       "789           staff          staff           2        2.94          0.000055   \n",
       "800         usually        usually           3        2.84          0.000099   \n",
       "805         effects         effect           2        2.90          0.000051   \n",
       "822            save           save           6        2.91          0.000466   \n",
       "826         provide        provide          18        2.88          0.003908   \n",
       "1068       directly       directly           3        3.08          0.000172   \n",
       "827          future         future           7        2.67          0.000365   \n",
       "867      relatively     relatively           3        3.31          0.000292   \n",
       "885        practice       practice           1        2.93          0.000014   \n",
       "889          choice         choice           2        2.92          0.000053   \n",
       "892        frequent       frequent           2        3.70          0.000318   \n",
       "905     preparation    preparation           1        3.62          0.000066   \n",
       "907      experience     experience           3        2.71          0.000073   \n",
       "914            fast           fast           3        2.91          0.000116   \n",
       "840        numerous       numerous           2        3.30          0.000127   \n",
       "1070    appropriate    appropriate           1        3.29          0.000031   \n",
       "1083        similar        similar           1        2.77          0.000009   \n",
       "1086            add            add           2        2.93          0.000054   \n",
       "1219         freely         freely           5        3.89          0.003085   \n",
       "1226        express        express           1        3.32          0.000033   \n",
       "1246  communication  communication           1        3.31          0.000032   \n",
       "1253      influence      influence           1        3.18          0.000024   \n",
       "1255           loss           loss           1        2.95          0.000014   \n",
       "1256      advantage      advantage           1        3.21          0.000026   \n",
       "1260         advice         advice           1        3.12          0.000021   \n",
       "1216          adult          adult           1        3.24          0.000028   \n",
       "1271        writing        writing           5        2.94          0.000346   \n",
       "1285     containing        contain           4        3.43          0.000685   \n",
       "\n",
       "      cluster  \n",
       "0           0  \n",
       "941         0  \n",
       "959         0  \n",
       "966         0  \n",
       "967         0  \n",
       "968         0  \n",
       "972         0  \n",
       "983         0  \n",
       "990         0  \n",
       "994         0  \n",
       "1001        0  \n",
       "1002        0  \n",
       "2020        0  \n",
       "1011        0  \n",
       "1014        0  \n",
       "1067        0  \n",
       "936         0  \n",
       "931         0  \n",
       "927         0  \n",
       "924         0  \n",
       "787         0  \n",
       "788         0  \n",
       "789         0  \n",
       "800         0  \n",
       "805         0  \n",
       "822         0  \n",
       "826         0  \n",
       "1068        0  \n",
       "827         0  \n",
       "867         0  \n",
       "885         0  \n",
       "889         0  \n",
       "892         0  \n",
       "905         0  \n",
       "907         0  \n",
       "914         0  \n",
       "840         0  \n",
       "1070        0  \n",
       "1083        0  \n",
       "1086        0  \n",
       "1219        0  \n",
       "1226        0  \n",
       "1246        0  \n",
       "1253        0  \n",
       "1255        0  \n",
       "1256        0  \n",
       "1260        0  \n",
       "1216        0  \n",
       "1271        0  \n",
       "1285        0  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['cluster'], ascending=True).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 overall words\n",
      "34 words included\n",
      "24 words without duplicate included\n",
      "Keywords: 3\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Let's take a ride in my new car. I will drive you home in my car. I love cars, which drive very fast and loud. Trucks and vans are the best. You can also cook in the back of my car. Food, meals and drinks are very tasty. My mother is all in to cooking good meals, foods and healthy dishes. This keeps me healthy while. I love the pasta and pies she bakes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[8]._.is_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['car', 'drive', 'fast', 'truck', 'van', 'good', 'cook', 'meal', 'food', 'healthy', 'dish', 'pasta', 'pie', 'bake']]\n"
     ]
    }
   ],
   "source": [
    "words = [[token.lemma_ for token in doc if not token._.is_excluded]]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>appearance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>relativ freqency</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cars</td>\n",
       "      <td>car</td>\n",
       "      <td>1</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.261916</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drive</td>\n",
       "      <td>drive</td>\n",
       "      <td>1</td>\n",
       "      <td>2.91</td>\n",
       "      <td>4.836455</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fast</td>\n",
       "      <td>fast</td>\n",
       "      <td>1</td>\n",
       "      <td>2.91</td>\n",
       "      <td>4.836455</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trucks</td>\n",
       "      <td>truck</td>\n",
       "      <td>1</td>\n",
       "      <td>3.45</td>\n",
       "      <td>16.757296</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vans</td>\n",
       "      <td>van</td>\n",
       "      <td>1</td>\n",
       "      <td>3.20</td>\n",
       "      <td>9.427639</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>best</td>\n",
       "      <td>good</td>\n",
       "      <td>2</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.802679</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cooking</td>\n",
       "      <td>cook</td>\n",
       "      <td>1</td>\n",
       "      <td>3.37</td>\n",
       "      <td>13.931710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meals</td>\n",
       "      <td>meal</td>\n",
       "      <td>1</td>\n",
       "      <td>3.53</td>\n",
       "      <td>20.165559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>foods</td>\n",
       "      <td>food</td>\n",
       "      <td>1</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.261916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>2</td>\n",
       "      <td>3.22</td>\n",
       "      <td>39.461625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dishes</td>\n",
       "      <td>dish</td>\n",
       "      <td>1</td>\n",
       "      <td>3.84</td>\n",
       "      <td>41.026483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pasta</td>\n",
       "      <td>pasta</td>\n",
       "      <td>1</td>\n",
       "      <td>4.14</td>\n",
       "      <td>82.166298</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pies</td>\n",
       "      <td>pie</td>\n",
       "      <td>1</td>\n",
       "      <td>3.82</td>\n",
       "      <td>39.396291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bakes</td>\n",
       "      <td>bake</td>\n",
       "      <td>1</td>\n",
       "      <td>4.17</td>\n",
       "      <td>88.000591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token    lemma  appearance  difficulty  relativ freqency  cluster\n",
       "0      cars      car           1        2.58          2.261916        3\n",
       "1     drive    drive           1        2.91          4.836455        3\n",
       "2      fast     fast           1        2.91          4.836455        3\n",
       "3    Trucks    truck           1        3.45         16.757296        3\n",
       "4      vans      van           1        3.20          9.427639        3\n",
       "5      best     good           2        1.88          1.802679        3\n",
       "6   cooking     cook           1        3.37         13.931710        1\n",
       "7     meals     meal           1        3.53         20.165559        1\n",
       "8     foods     food           1        2.58          2.261916        1\n",
       "9   healthy  healthy           2        3.22         39.461625        1\n",
       "10   dishes     dish           1        3.84         41.026483        1\n",
       "11    pasta    pasta           1        4.14         82.166298        1\n",
       "12     pies      pie           1        3.82         39.396291        1\n",
       "13    bakes     bake           1        4.17         88.000591        1"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for token in doc:\n",
    "    if not token._.is_excluded:\n",
    "        data.append((token, token.lemma_, token._.appearance, token._.difficulty, token._.relativ_freq, token._.cluster))\n",
    "df = pd.DataFrame(data, columns=['token', 'lemma', 'appearance', 'difficulty', 'relativ freqency', 'cluster'])\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3, 3: 6, 1: 8, 2: 1})"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.cluster_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Deep learning (also known as deep structured learning) is part of a broader family \n",
    "of machine learning methods based on artificial neural networks with representation \n",
    "        learning. Learning can be supervised, semi-supervised or unsupervised.[1][2][3]Deep-learning \n",
    "        architectures such as deep neural networks, deep belief networks, recurrent neural networks \n",
    "        and convolutional neural networks have been applied to fields including computer vision, \n",
    "        machine vision, speech recognition, natural language processing, audio recognition, social \n",
    "        network filtering, machine translation, bioinformatics, drug design, medical image analysis, \n",
    "        material inspection and board game programs, where they have produced results comparable \n",
    "        to and in some cases surpassing human expert performance.[4][5][6]Artificial neural networks \n",
    "        (ANNs) were inspired by information processing and distributed communication nodes in biological \n",
    "        systems. ANNs have various differences from biological brains. Specifically, neural networks tend \n",
    "        to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) \n",
    "        and analogue.[7][8][9]The adjective \"deep\" in deep learning refers to the use of multiple layers in \n",
    "        the network. Early work showed that a linear perceptron cannot be a universal classifier, and then \n",
    "        that a network with a nonpolynomial activation function with one hidden layer of unbounded width \n",
    "        can on the other hand so be. Deep learning is a modern variation which is concerned with an unbounded\n",
    "        number of layers of bounded size, which permits practical application and optimized implementation, \n",
    "        while retaining theoretical universality under mild conditions. In deep learning the layers are \n",
    "        also permitted to be heterogeneous and to deviate widely from biologically informed connectionist \n",
    "        models, for the sake of efficiency, trainability and understandability, whence the \"structured\" part.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257 overall words\n",
      "156 words included\n",
      "114 words without duplicate included\n",
      "17 keywords found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-77-6e5208dea2dd>:19: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  kw_score = token.similarity(kw)\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3938454\n",
      "0.5744245\n",
      "0.33924755\n",
      "0.47624484\n",
      "0.43483993\n",
      "0.3270241\n",
      "1.0\n",
      "0.52090365\n",
      "0.4847936\n",
      "0.46523783\n",
      "0.49933636\n",
      "0.8762495\n",
      "0.44071323\n",
      "0.2955146\n",
      "0.25625694\n",
      "0.2955146\n",
      "0.5744245\n",
      "0.40140018\n",
      "0.5100599\n",
      "0.31690955\n",
      "0.22550173\n",
      "0.44786528\n",
      "0.38716203\n",
      "0.4775482\n",
      "0.53911096\n",
      "0.41549888\n",
      "0.4988885\n",
      "1.0\n",
      "0.5007288\n",
      "0.4610773\n",
      "1.0\n",
      "0.40415663\n",
      "0.5314103\n",
      "0.37051588\n",
      "0.40864474\n",
      "0.38324967\n",
      "0.48531094\n",
      "0.45266506\n",
      "0.38082403\n",
      "0.50242513\n",
      "1.0\n",
      "0.40681517\n",
      "0.31428733\n",
      "1.0\n",
      "0.43199307\n",
      "0.4897565\n",
      "1.0\n",
      "0.4878846\n",
      "0.36730403\n",
      "1.0\n",
      "0.59545803\n",
      "0.45384392\n",
      "0.36053327\n",
      "1.0\n",
      "0.46185136\n",
      "1.0\n",
      "0.43217084\n",
      "1.0\n",
      "0.52928066\n",
      "0.4549633\n",
      "0.3777898\n",
      "0.43885174\n",
      "0.35806483\n",
      "0.34795207\n",
      "0.43768883\n",
      "0.35460824\n",
      "0.6406614\n",
      "0.4451714\n",
      "0.47006604\n",
      "0.26633573\n",
      "0.36964554\n",
      "0.47620687\n",
      "0.45806268\n",
      "1.0\n",
      "0.3019013\n",
      "0.4692436\n",
      "0.44344023\n",
      "0.34928936\n",
      "1.0\n",
      "0.31417662\n",
      "0.0\n",
      "1.0\n",
      "0.48357797\n",
      "0.31554163\n",
      "1.0\n",
      "0.40788516\n",
      "0.48470917\n",
      "0.5270915\n",
      "0.38272974\n",
      "0.47252935\n",
      "0.50294\n",
      "0.49841097\n",
      "0.34320146\n",
      "0.44353783\n",
      "1.0\n",
      "0.5282285\n",
      "0.4437383\n",
      "0.45886028\n",
      "0.42962694\n",
      "0.59137577\n",
      "0.49776393\n",
      "0.23172696\n",
      "0.38636324\n",
      "0.4387642\n",
      "0.20261705\n",
      "0.3956485\n",
      "0.6638554\n",
      "0.51560885\n",
      "0.24427068\n",
      "0.34175387\n",
      "0.31902835\n",
      "0.42425045\n",
      "0.24197689\n",
      "0.21963838\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if not token._.is_excluded:\n",
    "        print(token._.keyword_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TextAnalytics2.2] *",
   "language": "python",
   "name": "conda-env-TextAnalytics2.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
